{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "12e91914-5f51-43fa-b65b-625e73b4d17b",
      "metadata": {
        "id": "12e91914-5f51-43fa-b65b-625e73b4d17b"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
        "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp?1\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf",
      "metadata": {
        "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf"
      },
      "source": [
        "# Chapter 7: Finetuning To Follow Instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "L9DvrsHQR6FF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9DvrsHQR6FF",
        "outputId": "544d086b-40ec-4dba-bf56-56e38751e272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "UKT_y_kLSHhN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKT_y_kLSHhN",
        "outputId": "d338475e-cc14-4e22-c5a1-98c5abaaa159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Research/GPT2-Fine-Tuning\n"
          ]
        }
      ],
      "source": [
        "# !mkdir /content/drive/MyDrive/Research/\n",
        "%cd /content/drive/MyDrive/Research/GPT2-Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJtHgl-FLBNL",
        "outputId": "8908fa4b-9a7a-4801-b68c-3ce450ba1e46"
      },
      "id": "oJtHgl-FLBNL",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ch07.ipynb  gpt_model_code.py  NepaliBPE\t     __pycache__\n",
            "data.json   gpt_model.py       previous_chapters.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "Rb34vm442-rD",
      "metadata": {
        "id": "Rb34vm442-rD"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
        "outputId": "8d693ad0-4b31-4020-c3a4-97b7cb10f573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.10.0\n",
            "tiktoken version: 0.9.0\n",
            "torch version: 2.6.0+cu124\n",
            "tqdm version: 4.67.1\n",
            "tensorflow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "\n",
        "pkgs = [\n",
        "    \"matplotlib\",  # Plotting library\n",
        "    \"tiktoken\",    # Tokenizer\n",
        "    \"torch\",       # Deep learning library\n",
        "    \"tqdm\",        # Progress bar\n",
        "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
        "]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "264fca98-2f9a-4193-b435-2abfa3b4142f",
      "metadata": {
        "id": "264fca98-2f9a-4193-b435-2abfa3b4142f"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/overview.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813",
      "metadata": {
        "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813"
      },
      "source": [
        "## 7.1 Introduction to instruction finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab",
      "metadata": {
        "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab"
      },
      "source": [
        "- In chapter 5, we saw that pretraining an LLM involves a training procedure where it learns to generate one word at a time\n",
        "- Hence, a pretrained LLM is good at text completion, but it is not good at following instructions\n",
        "- In this chapter, we teach the LLM to follow instructions better"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18dc0535-0904-44ed-beaf-9b678292ef35",
      "metadata": {
        "id": "18dc0535-0904-44ed-beaf-9b678292ef35"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/instruction-following.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8",
      "metadata": {
        "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8"
      },
      "source": [
        "- The topics covered in this chapter are summarized in the figure below\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-1.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86",
      "metadata": {
        "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86"
      },
      "source": [
        "## 7.2 Preparing a dataset for supervised instruction finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8b34ff8-619f-4e89-bd03-ce513269760d",
      "metadata": {
        "id": "f8b34ff8-619f-4e89-bd03-ce513269760d"
      },
      "source": [
        "- We will work with an instruction dataset I prepared for this chapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "npMdH0Zjho2G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "npMdH0Zjho2G",
        "outputId": "fb55e53b-57e7-4958-fa75-0dcc1c59bf0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'नुवाकोटको तारकेश्वर गाउँपालिका ५ को बिर्ता व्यथा त्यो जिल्लाका अन्यत्रभन्दा बिल्कुल फरक छ । जिल्लाका राजनीतिकर्मी र भूमि अभियन्ताका अनुसार नुवाकोटमा सबैभन्दा बढी बिर्तापीडित किसान यही वडामा बस्छन् । जिल्लाभरिमै बिर्ता समस्याले सबैभन्दा गाँजेको यस वडाका जमिन जोत्ने किसानलाई शताब्दीऔंदेखि सरकारी अड्डाले अल्झाइरहेको छ ।'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Probably should `clean_data(new_crawled_data)` before merging `new_crawled_data.csv` and previous`cleaned_data.csv`\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class CleanData:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        # return text\n",
        "    # Example of removing HTML tags\n",
        "    def clean_html(self, text):\n",
        "        '''\n",
        "        # HTML Tag Removal:\n",
        "        * removes html tags like: <h1>\n",
        "        * Removes css or js code inside <style> and <script> tags\n",
        "        '''\n",
        "        soup = BeautifulSoup(text, \"lxml\")\n",
        "\n",
        "        # Remove all <script> and <style> tags\n",
        "        for script_or_style in soup(['script', 'style']):\n",
        "            script_or_style.decompose()\n",
        "\n",
        "        # Get text from the modified HTML\n",
        "        text = soup.get_text(separator=' ', strip=True)\n",
        "        # print(text)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def convert_to_devanagari_digits(self, input_string):\n",
        "        # Function to convert 0-9 to ० - ९\n",
        "        # i.e. Mapping of ASCII digits to Devanagari digits\n",
        "        devanagari_digits = {\n",
        "            '0': '०',\n",
        "            '1': '१',\n",
        "            '2': '२',\n",
        "            '3': '३',\n",
        "            '4': '४',\n",
        "            '5': '५',\n",
        "            '6': '६',\n",
        "            '7': '७',\n",
        "            '8': '८',\n",
        "            '9': '९'\n",
        "        }\n",
        "        # Convert each digit in the input string\n",
        "        result = ''.join(devanagari_digits[char] if char in devanagari_digits else char for char in input_string)\n",
        "        return result\n",
        "\n",
        "\n",
        "    def remove_non_devanagari_characters(self, text, keep_special_characters=True):\n",
        "        '''\n",
        "            # Function to find nepali sequences.\n",
        "            * keep punctuations if they occur between devanagari characters.\n",
        "            * Remove punctuation if previous character is not devanagari.\n",
        "            # Examples\n",
        "            texts = [\n",
        "                \"उनले दुहेको दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे। \\\"hi there\\\". what is your name? उनले दुहेको दूध\",\n",
        "                \"\\\"hi there. \\\"उनले दुहेको\\\" दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे। hi there. what is your name? उनले दुहेको दूध\\\"\",\n",
        "                \"name? उनले दुहेको दूध\\\"\"    #output: (last quatation, name?) should be ignored\n",
        "                ]\n",
        "\n",
        "            for text in texts:\n",
        "                removed = remove_non_devanagari_characters(text)\n",
        "                print(f'text: {text}, \\nclen: {removed}\\n\\n')\n",
        "\n",
        "\n",
        "            # output\n",
        "            text: उनले दुहेको दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे। \"hi there\". what is your name? उनले दुहेको दूध,\n",
        "            clen: उनले दुहेको दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे।             उनले दुहेको दूध\n",
        "\n",
        "\n",
        "            text: \"hi there. \"उनले दुहेको\" दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे। hi there. what is your name? उनले दुहेको दूध\",\n",
        "            clen:    \"उनले दुहेको दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे।             उनले दुहेको दूध\"\n",
        "\n",
        "\n",
        "            text: name? उनले दुहेको दूध\",\n",
        "            clen:  उनले दुहेको दूध\"\n",
        "        '''\n",
        "        def is_devanagari(char):\n",
        "            pattern=r'[ऀ-ॿ]'\n",
        "            return bool(re.match(pattern, char))\n",
        "\n",
        "        if not keep_special_characters:\n",
        "            return re.sub(r\"[^ऀ-ॿ ]\", \" \", text)\n",
        "\n",
        "        sequences = []\n",
        "        sequence = ''\n",
        "        punctuation_symbols = string.punctuation    # '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
        "        prefix_punctuations = '\\\"\\'(<[{'\n",
        "        index=0\n",
        "        while index < len(text):\n",
        "            char = text[index]\n",
        "            if is_devanagari(char) or char == ' ':\n",
        "                # Character is devanagari\n",
        "                sequence += char\n",
        "            elif char in punctuation_symbols:\n",
        "                # Character is punctuation\n",
        "                if sequence != '':\n",
        "                    if (len(text) > index+1) and not is_devanagari(text[index+1]):\n",
        "                        # e.g. गरे। \"hi there\" : skip quotation before hi\n",
        "                        pass\n",
        "                    else:\n",
        "                        sequence += char    # Sequence is no empty. i.e. previous char/sequence was devanagari otherwise ignore  punctuation\n",
        "                elif (len(text) > index+1) and is_devanagari(text[index+1]):\n",
        "                    # preserve prefix punctuations in devanagari. e.g. \"\"\"there. \\\"उनले \"\": preserve double-quotation before उनले\n",
        "                    sequence = char + text[index+1]\n",
        "                    index += 1  # another 1 is added at the end\n",
        "            else:\n",
        "                if sequence:\n",
        "                    sequences.append(sequence)\n",
        "                    sequence = ''   # Reset sequence\n",
        "            index += 1\n",
        "\n",
        "            # print(f'{sequences}\\n{sequence}\\n{char}{is_devanagari(char)}\\n\\n')\n",
        "        if sequence:    # last sequence\n",
        "            sequences.append(sequence)\n",
        "        return ' '.join(sequences)\n",
        "        # Example of using regex for special character removal\n",
        "\n",
        "    def normalize_data(self, text):\n",
        "      '''\n",
        "        * Standerize special characters\n",
        "        * e.g. convert different types of quotes to standard quotes\n",
        "      '''\n",
        "      characters_to_replace = {\n",
        "        '₹': 'रु',\n",
        "        'ʻ': \"'\",\n",
        "        'ː': ':',\n",
        "        '？': '?',\n",
        "        '‟': '\"',\n",
        "        '“' : '\"',\n",
        "        '”': '\"',\n",
        "        '`': \"'\",\n",
        "        '৷': '।',\n",
        "        'ˈ': \"'\",\n",
        "        '՛': \"'\",\n",
        "        'ǃ': '!',\n",
        "        '（': '(',\n",
        "        '：': ':',\n",
        "        'ˍ': '_',\n",
        "        '﹣': '-',\n",
        "        '״': '\"',\n",
        "        'ꞌ': \"'\",\n",
        "        '₋': '-',\n",
        "        '％': '%',\n",
        "        '꞉': ':',\n",
        "        '‵': \"'\"\n",
        "      }\n",
        "      # Replace each character in the dictionary with its corresponding standard character\n",
        "      for char, replacement in characters_to_replace.items():\n",
        "          text = text.replace(char, replacement)\n",
        "\n",
        "      return text\n",
        "\n",
        "    def clean_data(self, text):\n",
        "        # Remove HTML tags\n",
        "        text = self.clean_html(text)\n",
        "\n",
        "        # Normalize some characters\n",
        "        text = self.normalize_data(text)\n",
        "\n",
        "        # Convert 0-9 to ० - ९\n",
        "        text = self.convert_to_devanagari_digits(text)\n",
        "\n",
        "        text = self.remove_non_devanagari_characters(text, keep_special_characters=True)\n",
        "        # text = text.lower() # No lower characters in devanagari\n",
        "\n",
        "        # Replace one or more spaces with a single space\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        return text\n",
        "\n",
        "data_cleaner = CleanData()\n",
        "data_cleaner.clean_data('hi नुवाकोटको there तारकेश्वर गाउँपालिका–५ को बिर्ता–व्यथा त्यो जिल्लाका अन्यत्रभन्दा बिल्कुल फरक छ । जिल्लाका राजनीतिकर्मी र भूमि अभियन्ताका अनुसार, नुवाकोटमा सबैभन्दा बढी बिर्तापीडित किसान यही वडामा बस्छन् । जिल्लाभरिमै बिर्ता समस्याले सबैभन्दा गाँजेको यस वडाका जमिन जोत्ने किसानलाई शताब्दीऔंदेखि सरकारी अड्डाले अल्झाइरहेको छ ।')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "zVcbmq25hbcG",
      "metadata": {
        "id": "zVcbmq25hbcG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c4c27f-3348-45bb-851c-f1817c5fd4fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52005"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "!pip install datasets --quiet\n",
        "from datasets import load_dataset\n",
        "\n",
        "'''\n",
        "# Dataset: Saugatkafley/alpaca-nepali-sft\n",
        "\n",
        "- rows: instruction, input, output\n",
        "'''\n",
        "\n",
        "ds = load_dataset(\"Saugatkafley/alpaca-nepali-sft\")\n",
        "data = [d for d in ds['train']]\n",
        "\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect language\n",
        "- langid is faster but langdetect is more accurate\n",
        "- also there is this issue with langdetect: [choose one or other lang.](https://stackoverflow.com/questions/37235932/python-langdetect-choose-between-one-language-or-the-other-only)\n",
        "- so using langid (as you can make it choose betn `ne`, `en` since dataset by wiseyak is either nepali or english)"
      ],
      "metadata": {
        "id": "7lqp6bBrf4Gg"
      },
      "id": "7lqp6bBrf4Gg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Langdetect example\n",
        "```!pip install langdetect --quiet\n",
        "from langdetect import detect, DetectorFactory\n",
        "DetectorFactory.seed = 0  # To make results deterministic\n",
        "\n",
        "def is_nepali(text):\n",
        "    try:\n",
        "        return detect(text) == \"ne\"\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Example Usage\n",
        "text = \"यो नेपाली भाषा what do you mean हो।\"\n",
        "print(is_nepali(text))  # Output: True\n",
        "```\n"
      ],
      "metadata": {
        "id": "4ohoq0v0aZyo"
      },
      "id": "4ohoq0v0aZyo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### langid example\n",
        "```!pip install langid --quiet\n",
        "import langid\n",
        "\n",
        "def is_nepali(text):\n",
        "    langid.set_languages(['ne', 'en'])  # ISO 639-1 codes\n",
        "    lang, score = langid.classify(text)\n",
        "    # print(lang) # ne or en\n",
        "    return lang == \"ne\"\n",
        "\n",
        "# Example Usage\n",
        "print(is_nepali('\"यो नेपाली भाषा what do you mean  हो।\"'))  # Output: True\n",
        "print(is_nepali('यो नेपाली भाषा what do you mean  हो।'))  # Output: True\n",
        "print(is_nepali('Is this text english or nepali?'))  # Output: False\n",
        "```"
      ],
      "metadata": {
        "id": "bTUgtBaUdTnc"
      },
      "id": "bTUgtBaUdTnc"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langid --quiet"
      ],
      "metadata": {
        "id": "knkOOY3Zu_Jy"
      },
      "id": "knkOOY3Zu_Jy",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Dataset: Wiseyak/Wiseyak-SFT-Mixed-ne-en\n",
        "\n",
        "- rows: instruction, input, output\n",
        "- dataset contains mixed english and nepali text data\n",
        "\n",
        "- using langdetect (by google) to detect nepali language\n",
        "- library:langid is faster but langdetect seems to be more accurate\n",
        "'''\n",
        "\n",
        "from datasets import load_dataset\n",
        "import langid\n",
        "\n",
        "# Load the dataset\n",
        "ds = load_dataset(\"Wiseyak/Wiseyak-SFT-Mixed-ne-en\")\n",
        "\n",
        "langid.set_languages(['ne', 'en'])  # ISO 639-1 codes\n",
        "# Function to check if any field contains Nepali text\n",
        "def is_nepali(text):\n",
        "    lang, score = langid.classify(text)\n",
        "    # print(lang) # ne or en\n",
        "    return lang == \"ne\"\n",
        "\n",
        "# Filter dataset to include only rows where instruction, input, or output is Nepali\n",
        "filtered_data = [d for d in ds['train'] if is_nepali(d['instruction']) and is_nepali(d['input']) and is_nepali(d['output'])]\n",
        "data += filtered_data\n",
        "\n",
        "# Example: Print first 3 filtered rows\n",
        "for row in filtered_data[:3]:\n",
        "    print(row)\n",
        "\n",
        "print(f\"len. entries before filtering: {len(ds['train'])}\")\n",
        "print(f\"len. entries after filtering: {len(filtered_data)}\")\n",
        "print(f'len. data: {len(data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "12aa86ab7ccd4d04ae05145cee2ace25",
            "edd8c72bc25b42059f134ecc3b302c44",
            "fc72e11e7fc740e8a8bcd325224eb1f7",
            "c6f4679bc08d48b281a4a49fa557f290",
            "6b76b45fbb3e4abdb271e83429d80071",
            "b40bef8d56fa413aa805fb7f16e53232",
            "a4c6e024e4e84ab6b923b17dd49f2063",
            "0cc80e439e99440a9f837768be4d6e28",
            "f070fd4abb6c417799af732624467359",
            "e430de5ac2b2480a8a33fabec7149caa",
            "ffff2e5683624bf1a29ce248544662b4",
            "f70b9835b1fd42a2837cf76c894661bf",
            "467484aec7e3487aa03c28bea096c903",
            "382e407c5e2640b0bcfa597727508c4d",
            "75448f76e86a417e85b2fa7f40c6589f",
            "8561f0070e304dc5b8956829f664a329",
            "cdf3ceb14eeb4e27856fe79c103332ae",
            "809231b736d4417e941ab684f8f483cc",
            "87be4eec65da4e009c2061f847ad6da1",
            "fc5ee43429894db1ae3afbc426368ffc",
            "c1d252bea60e47beba7a19f5e73b7bcb",
            "f8f4054069e04f21aeb76583fa985807",
            "2762d9882bc445bf92c15dce0b3bbb8f",
            "d9b99e8a7c64462dbe6503f542691718",
            "0c5fe1e2c485414e86005eebbb44b770",
            "9d7e756e12a748ea98de28870300857d",
            "e59c6b8df3464660ac383523e08b9f91",
            "d2ac73bd164940d6aa6f1fbf7c7841b4",
            "2e1751fb411e4b67a66afb7cca604f16",
            "9c076897308c403081c8a793dee2a419",
            "2369a38eb6444b49b0f5bf0188e8249d",
            "21875bc5b7f4479bb95dc7589e5906ff",
            "91351da4c2b54246aed65121da1f253f"
          ]
        },
        "id": "6maXmBS1fTDY",
        "outputId": "1e70284d-0463-4fa8-e0d6-c37b17e9a5e5"
      },
      "id": "6maXmBS1fTDY",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/744 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12aa86ab7ccd4d04ae05145cee2ace25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/71.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f70b9835b1fd42a2837cf76c894661bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/113751 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2762d9882bc445bf92c15dce0b3bbb8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'यस कोडलाई रिफ्याक्टर गर्नुहोस् र टिप्पणीहरू थप्नुहोस्।', 'input': 'डेफ फ्याक्टोरियलाइज (num):\\n\\nकारक = 1\\n\\nदायरामा आइका लागि (1, नम्बर):\\n\\nकारक * = i\\n\\n........................................................................................................................................................................................................\\n\\nरिटर्न फ्याक्टोरियल', 'output': '\"\"\\n\\n#यो एउटा प्रकार्य हो जसले दिइएको सङ्ख्याको फ्याक्टोरियल गणना गर्दछ।\\n\\nडेफ फ्याक्टोरियलाइज (num):\\n\\n#चर \\'कारक\\' लाई 1 मा सेट गर्नुहोस्\\n\\nकारक = 1\\n\\n#रेन्ज प्रकार्य प्रयोग गरेर 1 बाट \\'num\\' मा पुनरावृत्ति गर्नुहोस्\\n\\nदायरामा आइका लागि (1, नम्बर):\\n\\n#पुनरावृत्तिमा हालको सङ्ख्याद्वारा \\'कारक\\' चरलाई गुणन गर्नुहोस्\\n\\nकारक * = i\\n\\n#\\'फ्याक्टोरियल\\' को अन्तिम मान फिर्ता गर्नुहोस्\\n\\nरिटर्न फ्याक्टोरियल\\n\\n\"\"'}\n",
            "{'instruction': 'प्रदान गरिएको जानकारीको आधारमा, वाक्यको काललाई विगतबाट भविष्यमा परिवर्तन गरेर पुनः लेख्नुहोस्।', 'input': 'उनले घन्टौँसम्म सुन्दर पियानो बजाउँथिन् अनि त्यसपछि मध्यरात भएकाले रोकिइन्।', 'output': 'उनी घन्टौँसम्म सुन्दर पियानो बजाउँछिन् र त्यसपछि मध्यरात हुने हुनाले रोकिन्छिन्।'}\n",
            "{'instruction': 'सक्रिय आवाज प्रयोग गरेर निम्न वाक्यलाई पुनः लेख्नुहोस्।', 'input': 'समाचार प्रतिवेदन कप्तानले पढेका थिए।', 'output': 'कप्तानले समाचार पढेर सुनाए।'}\n",
            "len. entries before filtering: 113751\n",
            "len. entries after filtering: 11476\n",
            "len. data: 63481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "data2 wiseyak\n",
        "---"
      ],
      "metadata": {
        "id": "_8UHBVGFNSlC"
      },
      "id": "_8UHBVGFNSlC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"Wiseyak/Wiseyak-SFT-Mixed-ne-en\")\n",
        "data = [d for d in ds['train']]\n",
        "```"
      ],
      "metadata": {
        "id": "FAFBhRwrLloK"
      },
      "id": "FAFBhRwrLloK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "len(data) # 113751\n",
        "```"
      ],
      "metadata": {
        "id": "QbgTIpzbLeJh"
      },
      "id": "QbgTIpzbLeJh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "a=InstructionDataset(data, tokenizer)\n",
        "len(a)  # 46329\n",
        "```"
      ],
      "metadata": {
        "id": "YaN1sKLgNmwW"
      },
      "id": "YaN1sKLgNmwW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "/data2 wiseyak\n",
        "---"
      ],
      "metadata": {
        "id": "CkyIoAljNWtl"
      },
      "id": "CkyIoAljNWtl"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4xbxHTkus5jI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xbxHTkus5jI",
        "outputId": "a2de9de9-f08d-44a3-8422-5be0f680ab77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type: <class 'list'>, len:63481 \n",
            " sample: {'instruction': 'स्वस्थ रहन तीनवटा टिप्स दिनुहोस्।', 'input': '', 'output': '1. सन्तुलित आहार खानुहोस् र प्रशस्त फलफूल र तरकारीहरू समावेश गर्न निश्चित गर्नुहोस्।\\n2. आफ्नो शरीर सक्रिय र बलियो राख्न नियमित रूपमा व्यायाम गर्नुहोस्।\\n3. पर्याप्त निद्रा लिनुहोस् र एक सुत्ने तालिका कायम राख्नुहोस्।', 'id': 0}\n"
          ]
        }
      ],
      "source": [
        "print(f'type: {type(data)}, len:{len(data)} \\n sample: {data[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7af8176-4255-4e92-8c7d-998771733eb8",
      "metadata": {
        "id": "d7af8176-4255-4e92-8c7d-998771733eb8"
      },
      "source": [
        "- Each item in the `data` list we loaded from the JSON file above is a dictionary in the following form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "-LiuBMsHkzQV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LiuBMsHkzQV",
        "outputId": "ede23ca3-9dc4-401e-c96d-e53c6cc24cc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example entry:\n",
            " {'instruction': 'यसलाई थप संक्षिप्त बनाउन निम्न वाक्य सम्पादन गर्नुहोस्।', 'input': 'पाँच मिनेटमा आइपुग्नु पर्ने बस समात्न उनी दौडिएर बस स्टपमा पुगे ।', 'output': 'पाँच मिनेटमा आइपुग्ने भन्दै उनी दौडिएर बस स्टपमा पुगे ।', 'id': 50}\n"
          ]
        }
      ],
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46",
      "metadata": {
        "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46"
      },
      "source": [
        "- Note that the `'input'` field can be empty:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "uFInFxDDk2Je",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFInFxDDk2Je",
        "outputId": "5f99400a-5ef6-4035-bab6-78f219a29d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Another example entry:\n",
            " {'instruction': 'निम्न प्रकारको खानाको स्वाद प्रोफाइल वर्णन गर्नुहोस्', 'input': 'जापानी', 'output': 'जापानी व्यञ्जन यसको सूक्ष्म र नाजुक स्वादहरू द्वारा विशेषता हो, नमकीन, मीठो, खट्टा, र उमामी स्वादहरूको संयोजनको विशेषता। यसले तिनीहरूको प्राकृतिक स्वादको संरक्षणमा ध्यान केन्द्रित गरेर ताजा सामग्रीहरू पनि प्रयोग गर्दछ।', 'id': 999}\n"
          ]
        }
      ],
      "source": [
        "print(\"Another example entry:\\n\", data[999])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f034799a-6575-45fd-98c9-9d1012d0fd58",
      "metadata": {
        "id": "f034799a-6575-45fd-98c9-9d1012d0fd58"
      },
      "source": [
        "- Instruction finetuning is often referred to as \"supervised instruction finetuning\" because it involves training a model on a dataset where the input-output pairs are explicitly provided\n",
        "- There are different ways to format the entries as inputs to the LLM; the figure below illustrates two example formats that were used for training the Alpaca (https://crfm.stanford.edu/2023/03/13/alpaca.html) and Phi-3 (https://arxiv.org/abs/2404.14219) LLMs, respectively"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10",
      "metadata": {
        "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/prompt-style.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6",
      "metadata": {
        "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6"
      },
      "source": [
        "- In this chapter, we use Alpaca-style prompt formatting, which was the original prompt template for instruction finetuning\n",
        "- Below, we format the input that we will pass as input to the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "Jhk37nnJnkBh",
      "metadata": {
        "id": "Jhk37nnJnkBh"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"तल दियीएको निर्देशन को उचित प्रतिक्रिया दिनुहोस।\"\n",
        "        f\"\\n\\n### प्रतिक्रिया:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### इनपुट:\\n{entry['input']}\" if entry[\"input\"] and '<noinput>' not in entry['input'] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6",
      "metadata": {
        "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6"
      },
      "source": [
        "- A formatted response with input field looks like as shown below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "F9UQRfjzo4Js",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9UQRfjzo4Js",
        "outputId": "f715607b-3aba-4ce9-fd89-38d50b84c0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "तल दियीएको निर्देशन को उचित प्रतिक्रिया दिनुहोस।\n",
            "\n",
            "### प्रतिक्रिया:\n",
            "यसलाई थप संक्षिप्त बनाउन निम्न वाक्य सम्पादन गर्नुहोस्।\n",
            "\n",
            "### इनपुट:\n",
            "पाँच मिनेटमा आइपुग्नु पर्ने बस समात्न उनी दौडिएर बस स्टपमा पुगे ।\n",
            "\n",
            "### प्रतिक्रिया:\n",
            "पाँच मिनेटमा आइपुग्ने भन्दै उनी दौडिएर बस स्टपमा पुगे ।\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### प्रतिक्रिया:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "aFZVopbIlNfx",
      "metadata": {
        "id": "aFZVopbIlNfx"
      },
      "outputs": [],
      "source": [
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "-zf6oht6bIUQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zf6oht6bIUQ",
        "outputId": "76bb5224-db96-4ad9-9c8f-7d1929b311e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 53958\n",
            "Validation set length: 3175\n",
            "Test set length: 6348\n"
          ]
        }
      ],
      "source": [
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "dIQ7BkQO-wJl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIQ7BkQO-wJl",
        "outputId": "79f43215-2bfd-49f6-dfc6-744b05c108e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'instruction': 'स्वस्थ रहन तीनवटा टिप्स दिनुहोस्।',\n",
              "  'input': '',\n",
              "  'output': '1. सन्तुलित आहार खानुहोस् र प्रशस्त फलफूल र तरकारीहरू समावेश गर्न निश्चित गर्नुहोस्।\\n2. आफ्नो शरीर सक्रिय र बलियो राख्न नियमित रूपमा व्यायाम गर्नुहोस्।\\n3. पर्याप्त निद्रा लिनुहोस् र एक सुत्ने तालिका कायम राख्नुहोस्।',\n",
              "  'id': 0},\n",
              " {'instruction': 'तीन प्राथमिक रंगहरू के हुन्?',\n",
              "  'input': '',\n",
              "  'output': 'तीन प्राथमिक रंगहरू रातो, नीलो र पहेंलो हुन्।',\n",
              "  'id': 1},\n",
              " {'instruction': 'परमाणुको संरचना वर्णन गर्नुहोस्।',\n",
              "  'input': '',\n",
              "  'output': 'परमाणु एक न्यूक्लियसबाट बनेको हुन्छ, जसमा प्रोटोन र न्यूट्रोनहरू हुन्छन्, इलेक्ट्रोनहरूले घेरिएको हुन्छ जुन न्यूक्लियसको वरिपरि परिक्रमा गर्दछ। प्रोटोन र न्यूट्रोनहरूमा सकारात्मक चार्ज हुन्छ, जबकि इलेक्ट्रोनहरूमा नकारात्मक चार्ज हुन्छ, परिणामस्वरूप समग्र तटस्थ परमाणु हुन्छ। प्रत्येक कणको संख्याले परमाणु संख्या र परमाणुको प्रकार निर्धारण गर्दछ।',\n",
              "  'id': 2},\n",
              " {'instruction': 'हामी वायु प्रदूषण कसरी कम गर्न सक्छौं?',\n",
              "  'input': '',\n",
              "  'output': 'नवीकरणीय ऊर्जा स्रोतहरूमा सर्ने, सार्वजनिक यातायातको प्रयोगलाई प्रोत्साहन गर्ने, जीवाश्म इन्धन जलाउन निषेध गर्ने, औद्योगिक स्रोतहरूबाट हुने उत्सर्जन कम गर्ने नीतिहरू लागू गर्ने, र सवारी साधनको उत्सर्जन मापदण्डहरू लागू गर्ने जस्ता वायु प्रदूषण कम गर्ने थुप्रै तरिकाहरू छन्। थप रूपमा, व्यक्तिहरूले कारको प्रयोग घटाएर, दाउरा जस्ता जलाउने सामग्रीहरू बेवास्ता गरेर, र ऊर्जा कुशल उपकरणहरूमा परिवर्तन गरेर वायु प्रदूषण कम गर्न आफ्नो भाग गर्न सक्छन्।',\n",
              "  'id': 3},\n",
              " {'instruction': 'तपाईंले कठिन निर्णय लिनु पर्ने समयको वर्णन गर्नुहोस्।',\n",
              "  'input': '',\n",
              "  'output': 'एउटा निर्माण कम्पनीमा परियोजना प्रबन्धकको रूपमा काम गर्दा मैले कठिन निर्णय लिनु परेको थियो। म ग्राहकको अपेक्षाहरू पूरा गर्नको लागि एक निश्चित मितिमा पूरा गर्न आवश्यक पर्ने परियोजनाको प्रभारी थिएँ। तर, अप्रत्याशित ढिलाइका कारण, हामीले समयसीमा पूरा गर्न सकेनौं र त्यसैले मैले कठिन निर्णय लिनु पर्यो। मैले म्याद लम्ब्याउने निर्णय गरें, तर मैले टोलीको स्रोतलाई अझ बढाएर बजेट बढाउनुपर्\\u200dयो। यद्यपि यो एक जोखिमपूर्ण निर्णय थियो, मैले अन्ततः परियोजना समयमै पूरा भएको र ग्राहकको अपेक्षाहरू पूरा भएको सुनिश्चित गर्न यसको साथ अगाडि बढ्ने निर्णय गरें। परियोजना अन्ततः सफलतापूर्वक सम्पन्न भयो र यो मेरो नेतृत्व र निर्णय गर्ने क्षमताको प्रमाणको रूपमा हेरिएको थियो।',\n",
              "  'id': 4},\n",
              " {'instruction': 'अनौठो बाहिर पहिचान गर्नुहोस्।',\n",
              "  'input': 'ट्विटर, इन्स्टाग्राम, टेलिग्राम',\n",
              "  'output': 'टेलिग्राम',\n",
              "  'id': 5},\n",
              " {'instruction': 'तलको अंश किन १/४ को बराबर छ भनेर व्याख्या गर्नुहोस्',\n",
              "  'input': '४/१६',\n",
              "  'output': 'अंश 4/16 1/4 को बराबर छ किनभने दुबै अंक र भाजकहरू 4 द्वारा भाग गर्न सकिन्छ। माथि र तल दुवै संख्याहरूलाई 4 ले भाग गर्दा अंश 1/4 प्राप्त हुन्छ।',\n",
              "  'id': 6},\n",
              " {'instruction': 'महत्त्वपूर्ण क्यारियर निर्णय लिनु पर्ने नायकको बारेमा तेस्रो व्यक्ति कथामा छोटो कथा लेख्नुहोस्।',\n",
              "  'input': '',\n",
              "  'output': 'जोन आफ्नो जीवनको एक चौराहेमा थिए। उसले भर्खर कलेजको स्नातक गरेको थियो र अब कुन क्यारियरको पछि लाग्ने भन्ने ठूलो निर्णयको सामना गरिरहेको थियो। धेरै सोचविचार पछि, उनले निर्णय गरे कि उनी लेखापाल बन्न र आर्थिक रूपमा विपन्नहरूलाई मद्दत गर्न चाहन्छन्। उहाँ सधैं नम्बरहरूमा राम्रो हुनुहुन्थ्यो र आफ्नो कामको मूर्त नतिजाहरू देखेर आनन्द लिनुभयो।\\n\\nजोनले लेखा पाठ्यक्रमहरूमा भर्ना गरे र सुरुमा यो धेरै चुनौतीपूर्ण पाए। उनले धेरै प्रणाली र नियमहरू चाँडै सिक्नुपर्\\u200dयो, तर उनले कडा मेहनत गरे र अन्ततः आफ्नो अध्ययनमा उत्कृष्ट भए। केही वर्षपछि जोनले आफ्नो सहरको एउटा लेखा फर्ममा काम गर्न थाले। उनी कर र लेखाको ज्ञानलाई वास्तविक संसारको सेटिङमा प्रयोग गर्न उत्सुक थिए।\\n\\nजोनले आफ्नो कामलाई माया गर्थे, किनकि यसले उसलाई आफ्ना ग्राहकहरूको पैसा बचत गर्न रणनीतिहरू खोज्नमा आफ्नो रचनात्मकता व्यक्त गर्न दिन्छ। फर्ममा केही वर्ष पछि, उनी एक वरिष्ठ लेखापाल बने र ठूला र थप चुनौतीपूर्ण केसहरू व्यवस्थापन गर्न भनियो। उहाँ अहिले वित्तीय उद्योगमा एक सम्मानित व्यक्तित्व हुनुहुन्थ्यो, तर उहाँ अझै पनि सम्झनुहुन्छ जब उहाँ भर्खरै कलेज स्नातक हुनुहुन्थ्यो, आफ्नो जीवनले उहाँलाई कुन दिशामा लैजान्छ भन्ने बारे अनिश्चित थिए।',\n",
              "  'id': 7},\n",
              " {'instruction': 'घरको 3D मोडेल रेन्डर गर्नुहोस्',\n",
              "  'input': '',\n",
              "  'output': '<nooutput> यस प्रकारको निर्देशन GPT मोडेलले पूरा गर्न सक्दैन।',\n",
              "  'id': 8},\n",
              " {'instruction': 'हिज्जे र व्याकरण त्रुटिहरूको लागि यो वाक्य मूल्याङ्कन गर्नुहोस्',\n",
              "  'input': 'उसले खाना पकाएर रेष्टुरेण्ट छोड्यो',\n",
              "  'output': 'खाना खाएर रेष्टुरेन्टबाट निस्कियो ।',\n",
              "  'id': 9}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "train_data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcaaf606-f913-4445-8301-632ae10d387d",
      "metadata": {
        "id": "fcaaf606-f913-4445-8301-632ae10d387d"
      },
      "source": [
        "## 7.3 Organizing data into training batches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233f63bd-9755-4d07-8884-5e2e5345cf27",
      "metadata": {
        "id": "233f63bd-9755-4d07-8884-5e2e5345cf27"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-2.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c",
      "metadata": {
        "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c"
      },
      "source": [
        "- We tackle this dataset batching in several steps, as summarized in the figure below\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/detailed-batching.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9af423f-aad9-4b3c-bea5-153021c04862",
      "metadata": {
        "id": "b9af423f-aad9-4b3c-bea5-153021c04862"
      },
      "source": [
        "- First, we implement an `InstructionDataset` class that pre-tokenizes all inputs in the dataset, similar to the `SpamDataset` in chapter 6\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/pretokenizing.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb",
      "metadata": {
        "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### प्रतिक्रिया:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            full_text = data_cleaner.clean_data(full_text)\n",
        "            encoded_text = tokenizer.encode(full_text)\n",
        "\n",
        "            # 512 is context length so only append encoded texts whose length is less than 512\n",
        "            if len(encoded_text)<=512:  # update\n",
        "              '''\n",
        "              `and len(encoded_text) >= 65`\n",
        "              setting min. length was to prevent english language entries (from wiseyak) but detecting language beforehand seems to be better approach.\n",
        "              '''\n",
        "              self.encoded_texts.append(\n",
        "                    encoded_text\n",
        "              )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_texts)  # update\n",
        "        # return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "MDz3-wPWnrJF",
      "metadata": {
        "id": "MDz3-wPWnrJF"
      },
      "outputs": [],
      "source": [
        "## load tokenizer\n",
        "import os\n",
        "import requests\n",
        "os.makedirs('NepaliBPE', exist_ok=True)\n",
        "\n",
        "res=requests.get(r\"https://raw.githubusercontent.com/Aananda-giri/GPT2-Nepali/main/2.%20tokenizer/NepaliBPE/tokenizer.json\")\n",
        "with open('NepaliBPE/tokenizer.json','w') as f:\n",
        "    f.write(res.text)\n",
        "\n",
        "res=requests.get(r\"https://raw.githubusercontent.com/Aananda-giri/GPT2-Nepali/main/2.%20tokenizer/NepaliBPE/tokenizer_config.json\")\n",
        "with open('NepaliBPE/tokenizer_config.json','w') as f:\n",
        "    f.write(res.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "fHddZf6lodro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124,
          "referenced_widgets": [
            "78dd1bf6d63344a294395ece64b58523",
            "c5a4d219898c420e89ba131c913690e4",
            "046c20ee19054545a7da0c2155ccc655",
            "4708e90d116748b2ada25c038626aeea",
            "43435e825a3542a5a1967bd2fa771b5a",
            "a25c7dc72fda44a5b26fd585d516eee4",
            "d7bb83a9396e4c9f8642c6b845764966",
            "115593a1493e4ff2877a71ba027b9153",
            "c6414a951d7945499da92576e2dc08d5",
            "5951e69c91f94ca38074e88b70b6022c",
            "5522f6e20e704a24a63c8b2fe57cb111"
          ]
        },
        "id": "fHddZf6lodro",
        "outputId": "2a5a67b8-410d-4f60-db56-3062c65d08a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78dd1bf6d63344a294395ece64b58523"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['राम</w>', 'ले</w>', 'भात</w>', 'खायो</w>', '।</w>']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "# Load your tokenizer\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('NepaliBPE')\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\"))\n",
        "tokenizer.tokenize('राम ले भात खायो। ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "vzvqEDbOF995",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzvqEDbOF995",
        "outputId": "f6b8a896-2654-411f-e29b-5fd30ace67a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1685, 285, 12434, 24801, 276]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "tokenizer.encode('राम ले भात खायो।')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "LnrOmoG5Ftk6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnrOmoG5Ftk6",
        "outputId": "29bfd5f1-94e7-4410-b8ad-3f58263beffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31699, 23105]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "tokenizer2 = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer2.encode(\"fuck hi\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "m9ir2gDPuPUK",
      "metadata": {
        "id": "m9ir2gDPuPUK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('data.json','w') as f:\n",
        "  json.dump(data,f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427",
      "metadata": {
        "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427"
      },
      "source": [
        "- In chapter 6, we padded all examples in a dataset to the same length\n",
        "  - Here, we take a more sophisticated approach and develop a custom \"collate\" function that we can pass to the data loader\n",
        "  - This custom collate function pads the training examples in each batch to have the same length (but different batches can have different lengths)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3",
      "metadata": {
        "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/padding.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "yXlaITO9_SRM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXlaITO9_SRM",
        "outputId": "2823f422-8c22-4de3-9c1e-ae72e110d304"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[50256]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "tokenizer2.encode(\"<|endoftext|>\",allowed_special={'<|endoftext|>'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "kvWff_gi_vEP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvWff_gi_vEP",
        "outputId": "dcce5eaa-9b66-4a90-e9ae-88e0d3684ac0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "tokenizer.encode(\"<|endoftext|>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca",
      "metadata": {
        "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=0, # 0 is index of <|endoftext|> token for our tokenizer  (was 50256 for GPT2 tokenizer)\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    # and increase the max length by +1, which will add one extra\n",
        "    # padding token below\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to batch_max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        # Via padded[:-1], we remove the extra padded token\n",
        "        # that has been added via the +1 setting in batch_max_length\n",
        "        # (the extra padding token will be relevant in later codes)\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
        "outputId": "56a09a7c-fb1f-476d-94db-cdbc57112303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3, 4],\n",
            "        [5, 6, 0, 0, 0],\n",
            "        [7, 8, 9, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_draft_1(batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b",
      "metadata": {
        "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/batching-step-4.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17769a19-b961-4213-92ef-34f441b2d1d6",
      "metadata": {
        "id": "17769a19-b961-4213-92ef-34f441b2d1d6"
      },
      "source": [
        "- Above, we only returned the inputs to the LLM; however, for LLM training, we also need the target values\n",
        "- Similar to pretraining an LLM, the targets are the inputs shifted by 1 position to the right, so the LLM learns to predict the next token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef",
      "metadata": {
        "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/inputs-targets.webp?1\" width=400px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc",
      "metadata": {
        "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=0, # 0 is index of <|endoftext|> token for our tokenizer (was 50256 for GPT2 tokenizer)\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
        "outputId": "b5e137f6-ded9-44e2-9579-1509724d71de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3, 4],\n",
            "        [5, 6, 0, 0, 0],\n",
            "        [7, 8, 9, 0, 0]])\n",
            "tensor([[1, 2, 3, 4, 0],\n",
            "        [6, 0, 0, 0, 0],\n",
            "        [8, 9, 0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15",
      "metadata": {
        "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15"
      },
      "source": [
        "- Next, we introduce an `ignore_index` value to replace all padding token IDs with a new value; the purpose of this `ignore_index` is that we can ignore padding values in the loss function (more on that later)\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/batching-step-5.webp?1\" width=500px>\n",
        "\n",
        "- Concretely, this means that we replace the token IDs corresponding to `50256` with `-100` as illustrated below"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd4bed33-956e-4b3f-a09c-586d8203109a",
      "metadata": {
        "id": "bd4bed33-956e-4b3f-a09c-586d8203109a"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/ignore-index.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5346513e-c3f4-44fe-af22-4ebd36497728",
      "metadata": {
        "id": "5346513e-c3f4-44fe-af22-4ebd36497728"
      },
      "source": [
        "- (In addition, we also introduce the `allowed_max_length` in case we want to limit the length of the samples; this will be useful if you plan to work with your own datasets that are longer than the 1024 token context size supported by the GPT-2 model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2",
      "metadata": {
        "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=0, # 0 is index of <|endoftext|> token for our tokenizer (was 50256 for GPT2 tokenizer)\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
        "outputId": "ab24d579-bb57-4a18-b9f1-3f4ceca5e579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2, 3, 4],\n",
            "        [5, 6, 0, 0, 0],\n",
            "        [7, 8, 9, 0, 0]])\n",
            "tensor([[   1,    2,    3,    4,    0],\n",
            "        [   6,    0, -100, -100, -100],\n",
            "        [   8,    9,    0, -100, -100]])\n"
          ]
        }
      ],
      "source": [
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7",
      "metadata": {
        "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7"
      },
      "source": [
        "- Let's see what this replacement by -100 accomplishes\n",
        "- For illustration purposes, let's assume we have a small classification task with 2 class labels, 0 and 1, similar to chapter 6\n",
        "- If we have the following logits values (outputs of the last layer of the model), we calculate the following loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524",
      "metadata": {
        "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524"
      },
      "source": [
        "- In practice, it is also common to mask out the target token IDs that correspond to the instruction, as illustrated in the figure below (this is a recommended reader exercise after completing the chapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39",
      "metadata": {
        "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/mask-instructions.webp?1\" width=600px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96",
      "metadata": {
        "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96"
      },
      "source": [
        "## 7.4 Creating data loaders for an instruction dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50",
      "metadata": {
        "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50"
      },
      "source": [
        "- In this section, we use the `InstructionDataset` class and `custom_collate_fn` function to instantiate the training, validation, and test data loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fffe390-b226-4d5c-983f-9f4da773cb82",
      "metadata": {
        "id": "9fffe390-b226-4d5c-983f-9f4da773cb82"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-3.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "932677e9-9317-42e8-b461-7b0269518f97",
      "metadata": {
        "id": "932677e9-9317-42e8-b461-7b0269518f97"
      },
      "source": [
        "- Another additional detail of the previous `custom_collate_fn` function is that we now directly move the data to the target device (e.g., GPU) instead of doing it in the main training loop, which improves efficiency because it can be carried out as a background process when we use the `custom_collate_fn` as part of the data loader\n",
        "- Using the `partial` function from Python's `functools` standard library, we create a new function with the `device` argument of the original function pre-filled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "etpqqWh8phKc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etpqqWh8phKc",
        "outputId": "801e7fcb-c856-4110-fc5e-6fcf6f44ade2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# However, the resulting loss values may be slightly different.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c",
      "metadata": {
        "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=1024\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a",
      "metadata": {
        "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a"
      },
      "source": [
        "- Next, we instantiate the data loaders similar to previous chapters, except that we now provide our own collate function for the batching process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "BtWkgir6Hlpe",
      "metadata": {
        "id": "BtWkgir6Hlpe"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "1d097dc8-ad34-4f05-b435-e4147965f532",
      "metadata": {
        "id": "1d097dc8-ad34-4f05-b435-e4147965f532"
      },
      "outputs": [],
      "source": [
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pbYYJw7JO90h",
      "metadata": {
        "id": "pbYYJw7JO90h"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "xNYfKjpOO_Dl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNYfKjpOO_Dl",
        "outputId": "0017fefc-bd01-4c52-8e5d-d76441eb1ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "for data in train_loader:\n",
        "  print(print(data[0].shape, data[1].shape))\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "fVdRuzoFBhHJ",
      "metadata": {
        "id": "fVdRuzoFBhHJ"
      },
      "outputs": [],
      "source": [
        "# # Todo this is giving error\n",
        "# assert inputs.shape[0] == 8, f\"input shape 0 {inputs.shape[0]}\"\n",
        "# assert inputs.shape[1] < 300, f\"input shape 1 {inputs.shape[1]}\"\n",
        "# assert targets.shape[0] == 8, f\"input shape 0 {inputs.shape[0]}\"\n",
        "# assert targets.shape[1] < 300, f\"input shape 1 {inputs.shape[1]}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0",
      "metadata": {
        "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0"
      },
      "source": [
        "- Let's see what the dimensions of the resulting input and target batches look like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "GGs1AI3vHpnX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGs1AI3vHpnX",
        "outputId": "2990b05d-4363-4269-c84f-f001ca88bcc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 293]) torch.Size([8, 293])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 319]) torch.Size([8, 319])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 414]) torch.Size([8, 414])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 290]) torch.Size([8, 290])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 348]) torch.Size([8, 348])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 304]) torch.Size([8, 304])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 280]) torch.Size([8, 280])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 323]) torch.Size([8, 323])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 391]) torch.Size([8, 391])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 310]) torch.Size([8, 310])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 270]) torch.Size([8, 270])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 349]) torch.Size([8, 349])\n",
            "torch.Size([8, 283]) torch.Size([8, 283])\n",
            "torch.Size([8, 373]) torch.Size([8, 373])\n",
            "torch.Size([8, 249]) torch.Size([8, 249])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 365]) torch.Size([8, 365])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 245]) torch.Size([8, 245])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 330]) torch.Size([8, 330])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 276]) torch.Size([8, 276])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 369]) torch.Size([8, 369])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 371]) torch.Size([8, 371])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 402]) torch.Size([8, 402])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 300]) torch.Size([8, 300])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 291]) torch.Size([8, 291])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 287]) torch.Size([8, 287])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 296]) torch.Size([8, 296])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 334]) torch.Size([8, 334])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 50]) torch.Size([8, 50])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 418]) torch.Size([8, 418])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 265]) torch.Size([8, 265])\n",
            "torch.Size([8, 278]) torch.Size([8, 278])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 55]) torch.Size([8, 55])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 298]) torch.Size([8, 298])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 303]) torch.Size([8, 303])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 342]) torch.Size([8, 342])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 501]) torch.Size([8, 501])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 303]) torch.Size([8, 303])\n",
            "torch.Size([8, 343]) torch.Size([8, 343])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 299]) torch.Size([8, 299])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 475]) torch.Size([8, 475])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 323]) torch.Size([8, 323])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 333]) torch.Size([8, 333])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 299]) torch.Size([8, 299])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 282]) torch.Size([8, 282])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 378]) torch.Size([8, 378])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 437]) torch.Size([8, 437])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 347]) torch.Size([8, 347])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 475]) torch.Size([8, 475])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 308]) torch.Size([8, 308])\n",
            "torch.Size([8, 372]) torch.Size([8, 372])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 289]) torch.Size([8, 289])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 360]) torch.Size([8, 360])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 330]) torch.Size([8, 330])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 302]) torch.Size([8, 302])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 348]) torch.Size([8, 348])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 388]) torch.Size([8, 388])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 318]) torch.Size([8, 318])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 330]) torch.Size([8, 330])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 234]) torch.Size([8, 234])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 263]) torch.Size([8, 263])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 293]) torch.Size([8, 293])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 299]) torch.Size([8, 299])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 317]) torch.Size([8, 317])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 269]) torch.Size([8, 269])\n",
            "torch.Size([8, 269]) torch.Size([8, 269])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 335]) torch.Size([8, 335])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 452]) torch.Size([8, 452])\n",
            "torch.Size([8, 401]) torch.Size([8, 401])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 311]) torch.Size([8, 311])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 297]) torch.Size([8, 297])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 251]) torch.Size([8, 251])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 248]) torch.Size([8, 248])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 335]) torch.Size([8, 335])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 356]) torch.Size([8, 356])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 329]) torch.Size([8, 329])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 399]) torch.Size([8, 399])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 53]) torch.Size([8, 53])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 263]) torch.Size([8, 263])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 291]) torch.Size([8, 291])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 303]) torch.Size([8, 303])\n",
            "torch.Size([8, 304]) torch.Size([8, 304])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 310]) torch.Size([8, 310])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 439]) torch.Size([8, 439])\n",
            "torch.Size([8, 334]) torch.Size([8, 334])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 251]) torch.Size([8, 251])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 300]) torch.Size([8, 300])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 334]) torch.Size([8, 334])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 378]) torch.Size([8, 378])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 259]) torch.Size([8, 259])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 465]) torch.Size([8, 465])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 259]) torch.Size([8, 259])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 275]) torch.Size([8, 275])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 309]) torch.Size([8, 309])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 366]) torch.Size([8, 366])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 276]) torch.Size([8, 276])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 384]) torch.Size([8, 384])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 310]) torch.Size([8, 310])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 318]) torch.Size([8, 318])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 291]) torch.Size([8, 291])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 245]) torch.Size([8, 245])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 306]) torch.Size([8, 306])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 321]) torch.Size([8, 321])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 248]) torch.Size([8, 248])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 274]) torch.Size([8, 274])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 334]) torch.Size([8, 334])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 377]) torch.Size([8, 377])\n",
            "torch.Size([8, 259]) torch.Size([8, 259])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 333]) torch.Size([8, 333])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 288]) torch.Size([8, 288])\n",
            "torch.Size([8, 276]) torch.Size([8, 276])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 340]) torch.Size([8, 340])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 299]) torch.Size([8, 299])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 49]) torch.Size([8, 49])\n",
            "torch.Size([8, 327]) torch.Size([8, 327])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 270]) torch.Size([8, 270])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 318]) torch.Size([8, 318])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 355]) torch.Size([8, 355])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 327]) torch.Size([8, 327])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 348]) torch.Size([8, 348])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 290]) torch.Size([8, 290])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 278]) torch.Size([8, 278])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 380]) torch.Size([8, 380])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 313]) torch.Size([8, 313])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 311]) torch.Size([8, 311])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 268]) torch.Size([8, 268])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 275]) torch.Size([8, 275])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 429]) torch.Size([8, 429])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 275]) torch.Size([8, 275])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 343]) torch.Size([8, 343])\n",
            "torch.Size([8, 410]) torch.Size([8, 410])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 409]) torch.Size([8, 409])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 350]) torch.Size([8, 350])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 386]) torch.Size([8, 386])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 56]) torch.Size([8, 56])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 280]) torch.Size([8, 280])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 329]) torch.Size([8, 329])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 304]) torch.Size([8, 304])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 401]) torch.Size([8, 401])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 288]) torch.Size([8, 288])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 391]) torch.Size([8, 391])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 283]) torch.Size([8, 283])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 292]) torch.Size([8, 292])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 334]) torch.Size([8, 334])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 353]) torch.Size([8, 353])\n",
            "torch.Size([8, 278]) torch.Size([8, 278])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 368]) torch.Size([8, 368])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 311]) torch.Size([8, 311])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 258]) torch.Size([8, 258])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 274]) torch.Size([8, 274])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 258]) torch.Size([8, 258])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 282]) torch.Size([8, 282])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 326]) torch.Size([8, 326])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 291]) torch.Size([8, 291])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 318]) torch.Size([8, 318])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 294]) torch.Size([8, 294])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 393]) torch.Size([8, 393])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 328]) torch.Size([8, 328])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 300]) torch.Size([8, 300])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 251]) torch.Size([8, 251])\n",
            "torch.Size([8, 273]) torch.Size([8, 273])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 308]) torch.Size([8, 308])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 297]) torch.Size([8, 297])\n",
            "torch.Size([8, 287]) torch.Size([8, 287])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 349]) torch.Size([8, 349])\n",
            "torch.Size([8, 389]) torch.Size([8, 389])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 301]) torch.Size([8, 301])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 359]) torch.Size([8, 359])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 269]) torch.Size([8, 269])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 249]) torch.Size([8, 249])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 296]) torch.Size([8, 296])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 328]) torch.Size([8, 328])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 249]) torch.Size([8, 249])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 270]) torch.Size([8, 270])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 280]) torch.Size([8, 280])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 285]) torch.Size([8, 285])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 323]) torch.Size([8, 323])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 392]) torch.Size([8, 392])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 332]) torch.Size([8, 332])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 303]) torch.Size([8, 303])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 305]) torch.Size([8, 305])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 302]) torch.Size([8, 302])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 296]) torch.Size([8, 296])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 245]) torch.Size([8, 245])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 311]) torch.Size([8, 311])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 279]) torch.Size([8, 279])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 331]) torch.Size([8, 331])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 483]) torch.Size([8, 483])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 293]) torch.Size([8, 293])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 406]) torch.Size([8, 406])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 296]) torch.Size([8, 296])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 368]) torch.Size([8, 368])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 253]) torch.Size([8, 253])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 245]) torch.Size([8, 245])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 251]) torch.Size([8, 251])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 302]) torch.Size([8, 302])\n",
            "torch.Size([8, 447]) torch.Size([8, 447])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 52]) torch.Size([8, 52])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 251]) torch.Size([8, 251])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 387]) torch.Size([8, 387])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 287]) torch.Size([8, 287])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 291]) torch.Size([8, 291])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 288]) torch.Size([8, 288])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 471]) torch.Size([8, 471])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 371]) torch.Size([8, 371])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 434]) torch.Size([8, 434])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 367]) torch.Size([8, 367])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 234]) torch.Size([8, 234])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 265]) torch.Size([8, 265])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 339]) torch.Size([8, 339])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 375]) torch.Size([8, 375])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 393]) torch.Size([8, 393])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 449]) torch.Size([8, 449])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 459]) torch.Size([8, 459])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 269]) torch.Size([8, 269])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 294]) torch.Size([8, 294])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 325]) torch.Size([8, 325])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 357]) torch.Size([8, 357])\n",
            "torch.Size([8, 341]) torch.Size([8, 341])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 319]) torch.Size([8, 319])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 280]) torch.Size([8, 280])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 344]) torch.Size([8, 344])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 330]) torch.Size([8, 330])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 300]) torch.Size([8, 300])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 394]) torch.Size([8, 394])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 328]) torch.Size([8, 328])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 284]) torch.Size([8, 284])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 454]) torch.Size([8, 454])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 293]) torch.Size([8, 293])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 366]) torch.Size([8, 366])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 328]) torch.Size([8, 328])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 408]) torch.Size([8, 408])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 300]) torch.Size([8, 300])\n",
            "torch.Size([8, 317]) torch.Size([8, 317])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 292]) torch.Size([8, 292])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 325]) torch.Size([8, 325])\n",
            "torch.Size([8, 357]) torch.Size([8, 357])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 417]) torch.Size([8, 417])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 43]) torch.Size([8, 43])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 322]) torch.Size([8, 322])\n",
            "torch.Size([8, 382]) torch.Size([8, 382])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 274]) torch.Size([8, 274])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 468]) torch.Size([8, 468])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 234]) torch.Size([8, 234])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 279]) torch.Size([8, 279])\n",
            "torch.Size([8, 293]) torch.Size([8, 293])\n",
            "torch.Size([8, 328]) torch.Size([8, 328])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 357]) torch.Size([8, 357])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 320]) torch.Size([8, 320])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 249]) torch.Size([8, 249])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 350]) torch.Size([8, 350])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 275]) torch.Size([8, 275])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 317]) torch.Size([8, 317])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 339]) torch.Size([8, 339])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 280]) torch.Size([8, 280])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 258]) torch.Size([8, 258])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 381]) torch.Size([8, 381])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 288]) torch.Size([8, 288])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 298]) torch.Size([8, 298])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 248]) torch.Size([8, 248])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 338]) torch.Size([8, 338])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 290]) torch.Size([8, 290])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 285]) torch.Size([8, 285])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 494]) torch.Size([8, 494])\n",
            "torch.Size([8, 249]) torch.Size([8, 249])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 301]) torch.Size([8, 301])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 339]) torch.Size([8, 339])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 292]) torch.Size([8, 292])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 292]) torch.Size([8, 292])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 376]) torch.Size([8, 376])\n",
            "torch.Size([8, 337]) torch.Size([8, 337])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 263]) torch.Size([8, 263])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 434]) torch.Size([8, 434])\n",
            "torch.Size([8, 352]) torch.Size([8, 352])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 307]) torch.Size([8, 307])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 321]) torch.Size([8, 321])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 315]) torch.Size([8, 315])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 320]) torch.Size([8, 320])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 395]) torch.Size([8, 395])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 319]) torch.Size([8, 319])\n",
            "torch.Size([8, 401]) torch.Size([8, 401])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 253]) torch.Size([8, 253])\n",
            "torch.Size([8, 286]) torch.Size([8, 286])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 371]) torch.Size([8, 371])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 364]) torch.Size([8, 364])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 292]) torch.Size([8, 292])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 294]) torch.Size([8, 294])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 288]) torch.Size([8, 288])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 277]) torch.Size([8, 277])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 284]) torch.Size([8, 284])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 336]) torch.Size([8, 336])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 333]) torch.Size([8, 333])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 353]) torch.Size([8, 353])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 275]) torch.Size([8, 275])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 286]) torch.Size([8, 286])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 401]) torch.Size([8, 401])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 337]) torch.Size([8, 337])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 346]) torch.Size([8, 346])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 263]) torch.Size([8, 263])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 317]) torch.Size([8, 317])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 234]) torch.Size([8, 234])\n",
            "torch.Size([8, 403]) torch.Size([8, 403])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 253]) torch.Size([8, 253])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 305]) torch.Size([8, 305])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 303]) torch.Size([8, 303])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 248]) torch.Size([8, 248])\n",
            "torch.Size([8, 372]) torch.Size([8, 372])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 378]) torch.Size([8, 378])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 269]) torch.Size([8, 269])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 394]) torch.Size([8, 394])\n",
            "torch.Size([8, 299]) torch.Size([8, 299])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 293]) torch.Size([8, 293])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 360]) torch.Size([8, 360])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 276]) torch.Size([8, 276])\n",
            "torch.Size([8, 428]) torch.Size([8, 428])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 385]) torch.Size([8, 385])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 374]) torch.Size([8, 374])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 55]) torch.Size([8, 55])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 283]) torch.Size([8, 283])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 337]) torch.Size([8, 337])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 442]) torch.Size([8, 442])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 273]) torch.Size([8, 273])\n",
            "torch.Size([8, 390]) torch.Size([8, 390])\n",
            "torch.Size([8, 393]) torch.Size([8, 393])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 328]) torch.Size([8, 328])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 316]) torch.Size([8, 316])\n",
            "torch.Size([8, 284]) torch.Size([8, 284])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 279]) torch.Size([8, 279])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 308]) torch.Size([8, 308])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 436]) torch.Size([8, 436])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 333]) torch.Size([8, 333])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 253]) torch.Size([8, 253])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 270]) torch.Size([8, 270])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 491]) torch.Size([8, 491])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 358]) torch.Size([8, 358])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 339]) torch.Size([8, 339])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 292]) torch.Size([8, 292])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 258]) torch.Size([8, 258])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 299]) torch.Size([8, 299])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 313]) torch.Size([8, 313])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 303]) torch.Size([8, 303])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 249]) torch.Size([8, 249])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 279]) torch.Size([8, 279])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 342]) torch.Size([8, 342])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 306]) torch.Size([8, 306])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 439]) torch.Size([8, 439])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 318]) torch.Size([8, 318])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 284]) torch.Size([8, 284])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 380]) torch.Size([8, 380])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 310]) torch.Size([8, 310])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 251]) torch.Size([8, 251])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 269]) torch.Size([8, 269])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 369]) torch.Size([8, 369])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 295]) torch.Size([8, 295])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 290]) torch.Size([8, 290])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 395]) torch.Size([8, 395])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 466]) torch.Size([8, 466])\n",
            "torch.Size([8, 338]) torch.Size([8, 338])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 282]) torch.Size([8, 282])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 245]) torch.Size([8, 245])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 284]) torch.Size([8, 284])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 341]) torch.Size([8, 341])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 234]) torch.Size([8, 234])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 278]) torch.Size([8, 278])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 355]) torch.Size([8, 355])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 282]) torch.Size([8, 282])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 278]) torch.Size([8, 278])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 325]) torch.Size([8, 325])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 433]) torch.Size([8, 433])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 285]) torch.Size([8, 285])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 302]) torch.Size([8, 302])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 447]) torch.Size([8, 447])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 291]) torch.Size([8, 291])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 245]) torch.Size([8, 245])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 280]) torch.Size([8, 280])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 279]) torch.Size([8, 279])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 274]) torch.Size([8, 274])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 346]) torch.Size([8, 346])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 305]) torch.Size([8, 305])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 284]) torch.Size([8, 284])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 295]) torch.Size([8, 295])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 320]) torch.Size([8, 320])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 301]) torch.Size([8, 301])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 346]) torch.Size([8, 346])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 367]) torch.Size([8, 367])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 287]) torch.Size([8, 287])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 357]) torch.Size([8, 357])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 297]) torch.Size([8, 297])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 309]) torch.Size([8, 309])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 263]) torch.Size([8, 263])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 290]) torch.Size([8, 290])\n",
            "torch.Size([8, 273]) torch.Size([8, 273])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "count=0\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)\n",
        "    assert inputs.shape[0] == 8, f\"input shape 0 {inputs.shape[0]}\"\n",
        "    # assert inputs.shape[1] < 1000, f\"input shape 1 {inputs.shape[1]}\"\n",
        "    assert targets.shape[0] == 8, f\"input shape 0 {inputs.shape[0]}\"\n",
        "    # assert targets.shape[1] < 1000, f\"input shape 1 {inputs.shape[1]}\"\n",
        "    # count +=1\n",
        "    # if count>10:break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657",
      "metadata": {
        "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657"
      },
      "source": [
        "- As we can see based on the output above, all batches have a batch size of 8 but a different length, as expected\n",
        "- Let's also double-check that the inputs contain the `<|endoftext|>` padding tokens corresponding to token ID 50256 by printing the contents of the first training example in the `inputs` batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
        "outputId": "a8bd5910-1d44-471e-cdf3-ea104b69bb4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4051,   325,  8808,   298,  1771,   280,  3980,  4159,  4292,  8695,\n",
            "          276,  4159,   468,  2386, 20031,  5929, 16108,  9209,   276,  4159,\n",
            "         3307, 10210, 14013, 45678,  9722,   161,   573,   378,   247, 22188,\n",
            "        35512,  2627,   353,    59,  4511, 11969,   403,   276,  2384,  5450,\n",
            "         3072,  3131,   293,   691,  3949,  9021, 13332,  1889,   334,  2897,\n",
            "        17199, 40446,   691,  3055,  4330,   276,   330,  1339, 28112,  8831,\n",
            "        10344,  4074,   161,  6185,   972, 11049,   186,   276,  2384,  9989,\n",
            "        32023,  1088,  5929, 10521,   186,  1785, 10878,   536,  5845,  5845,\n",
            "          520,   276,  2384,   363,  6955,  6492,   290,  1662,   536,  6060,\n",
            "        35538,  5682, 10140,   501,   520,   911,  5425, 10739,   161,  2386,\n",
            "         1834,   691,   334,   276,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(inputs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360",
      "metadata": {
        "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360"
      },
      "source": [
        "- Similarly, we visually double-check that the targets contain the -100 placeholder tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
        "outputId": "c9fd01c7-3cca-4e8b-f692-4ea941ee721d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  325,  8808,   298,  1771,   280,  3980,  4159,  4292,  8695,   276,\n",
            "         4159,   468,  2386, 20031,  5929, 16108,  9209,   276,  4159,  3307,\n",
            "        10210, 14013, 45678,  9722,   161,   573,   378,   247, 22188, 35512,\n",
            "         2627,   353,    59,  4511, 11969,   403,   276,  2384,  5450,  3072,\n",
            "         3131,   293,   691,  3949,  9021, 13332,  1889,   334,  2897, 17199,\n",
            "        40446,   691,  3055,  4330,   276,   330,  1339, 28112,  8831, 10344,\n",
            "         4074,   161,  6185,   972, 11049,   186,   276,  2384,  9989, 32023,\n",
            "         1088,  5929, 10521,   186,  1785, 10878,   536,  5845,  5845,   520,\n",
            "          276,  2384,   363,  6955,  6492,   290,  1662,   536,  6060, 35538,\n",
            "         5682, 10140,   501,   520,   911,  5425, 10739,   161,  2386,  1834,\n",
            "          691,   334,   276,     0,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(targets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6aad445-8f19-4238-b9bf-db80767fb91a",
      "metadata": {
        "id": "d6aad445-8f19-4238-b9bf-db80767fb91a"
      },
      "source": [
        "## 7.5 Loading a pretrained LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a5c07d1-4fc9-4846-94cf-b11a085a667b",
      "metadata": {
        "id": "5a5c07d1-4fc9-4846-94cf-b11a085a667b"
      },
      "source": [
        "- In this section, we load a pretrained GPT model using the same code that we used in section 5.5 of chapter 5 and section 6.4 in chapter 6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d1b438f-88af-413f-96a9-f059c6c55fc4",
      "metadata": {
        "id": "8d1b438f-88af-413f-96a9-f059c6c55fc4"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-4.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c68eda7-e02e-4caa-846b-ca6dbd396ca2",
      "metadata": {
        "id": "8c68eda7-e02e-4caa-846b-ca6dbd396ca2"
      },
      "source": [
        "- However, instead of loading the smallest 124 million parameter model, we load the medium version with 355 million parameters since the 124 million model is too small for achieving qualitatively reasonable results via instruction finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "821H2j8-wA-W",
      "metadata": {
        "id": "821H2j8-wA-W"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "# modified.\n",
        "res = requests.get('https://raw.githubusercontent.com/Aananda-giri/GPT2-Nepali/main/3.%20GPT2-Nepali/2_inference/gpt_model_code.py')\n",
        "with open('gpt_model_code.py','w') as f:\n",
        "    f.write(res.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "uP8QGusPw_hF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "83e7f4df09c947bba4651a57e245caec",
            "59b7603d166747a6b4ec5c8b2663615f",
            "7840bb35972d49d7aabecc3679310a39",
            "dbefb28230734a9396970295b8aa40c1",
            "16a535ce3a0540d38427b848d7d9f724",
            "c5a7d47d2c484afda438f4d30e384353",
            "e6d5b704defd43109d8e504d405ec770",
            "3c03289a162f4665ad9da7eed76a5629",
            "e000427fcdbc46fa9c2f8ec9765f6a24",
            "0f68fdc697a24efd8247482209190015",
            "381ee4c0cc554816a066d3ee3c8d21ea",
            "902d74e63c904d409d9d38177cd98611",
            "f0dd48dd4af84d108816da0f859a9437",
            "5dd7c59ad9d0400ca307f0a94bdd5054",
            "28b6460138ab483f8739217089037bf3",
            "71e3df1690e94ef8a40e10c5ddbf55a7",
            "f4ed7c352b2c46c4ae7fcc9c4912a9c5",
            "ca3d854bc60b44fb98916cfba03ff82e",
            "f52e57167237411683e53f80b7111d37",
            "4f6ec3d692f943e4843b01c93d3d85b4",
            "eb6e39930e854ebe857f6854c3ac91cf",
            "a0de7080f8d84025a8c1c6c8f80f4f13"
          ]
        },
        "id": "uP8QGusPw_hF",
        "outputId": "adedfa68-82b1-4f75-93dd-283220e29641"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/196 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83e7f4df09c947bba4651a57e245caec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/661M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "902d74e63c904d409d9d38177cd98611"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "रामले भात दाल र तरकारी गरी दुई लाख २० हजार रुपैयाँ पाएका छन् ।\n"
          ]
        }
      ],
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from gpt_model_code import GPTModel, GPT_CONFIG_124M, generate\n",
        "\n",
        "\n",
        "# load the model\n",
        "# ----------------------------\n",
        "\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# checkpoint = torch.load('/kaggle/input/sebastian-v4/model_checkpoints/model_pg_190000_steps.pth', weights_only=False)\n",
        "# # modified (added model loading code)\n",
        "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "model = GPTModel.from_pretrained(\"Aananda-giri/GPT2-Nepali\")\n",
        "model.to(device)\n",
        "\n",
        "# load the tokenizer\n",
        "# ----------------------------\n",
        "# tokenizer = PreTrainedTokenizerFast.from_pretrained(\"Aananda-giri/NepaliBPE\")\n",
        "\n",
        "\n",
        "# generate a sample\n",
        "# ----------------------------\n",
        "\n",
        "prompt = \"रामले भात\"\n",
        "\n",
        "generated_text = generate(\n",
        "    model,\n",
        "    prompt,\n",
        "    tokenizer,\n",
        "    max_new_tokens=100,\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    top_p=None,  # New parameter for nucleus sampling\n",
        "    eos_id=None,\n",
        "    repetition_penalty=1.2,\n",
        "    penalize_len_below=50\n",
        ")\n",
        "\n",
        "model.eval();\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf3afed-bc8e-4d3a-ad9d-eb6f57bb7af5",
      "metadata": {
        "id": "dbf3afed-bc8e-4d3a-ad9d-eb6f57bb7af5"
      },
      "source": [
        "- Before we start finetuning the model in the next section, let's see how it performs on one of the validation tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "kPzOnCA-1now",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPzOnCA-1now",
        "outputId": "472e07de-6132-4bf2-f64f-dcdce191dd52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'थप रूपमा, इनपुटमा जनावरको सबैभन्दा प्रभावशाली विशेषताहरू मध्ये 5 सूचीबद्ध गर्नुहोस्',\n",
              " 'input': 'जनावरः पेन्गुइन',\n",
              " 'output': '1) पेन्गुइनहरू निपुण पौडी खेल्नेहरू हुन् र 22 माइल प्रति घण्टासम्मको गतिमा पुग्न सक्छन्।\\n\\n2) तिनीहरूसँग विशेष पंखहरू छन् जसले न्यानो, जलरोधक, र पौडी खेल्नका लागि सुव्यवस्थित रूप प्रदान गर्दछ।\\n\\n3) पेन्गुइनहरू सामाजिक जनावरहरू हुन् र हजारौँ चराहरू समावेश गर्न सक्ने रोकरीज भनिने उपनिवेशहरूमा बस्छन्।\\n\\n4) तिनीहरूसँग एक अद्वितीय संभोग अनुष्ठान छ जहाँ तिनीहरूले साथीलाई आकर्षित गर्न प्रेमालाप प्रदर्शन गर्छन्।\\n\\n5) तिनीहरू चिसो अन्टार्कटिकादेखि दक्षिण अमेरिका, अस्ट्रेलिया र अफ्रिकाको समशीतोष्ण तटीय क्षेत्रहरूमा बस्ने प्रजातिहरूसहित चरम वातावरणमा अनुकूल हुनमा असाधारण छन्।'}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "val_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "7bd32b7c-5b44-4d25-a09f-46836802ca74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bd32b7c-5b44-4d25-a09f-46836802ca74",
        "outputId": "c73b2829-9170-46bf-b188-8f76d690e824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "तल दियीएको निर्देशन को उचित प्रतिक्रिया दिनुहोस।\n",
            "\n",
            "### प्रतिक्रिया:\n",
            "थप रूपमा, इनपुटमा जनावरको सबैभन्दा प्रभावशाली विशेषताहरू मध्ये 5 सूचीबद्ध गर्नुहोस्\n",
            "\n",
            "### इनपुट:\n",
            "जनावरः पेन्गुइन\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_simple_code = '''\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()  # Calculate loss gradients\n",
        "            optimizer.step()  # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "'''"
      ],
      "metadata": {
        "id": "7jSWaK0tWEXX"
      },
      "id": "7jSWaK0tWEXX",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "R9shGC3O0drk",
      "metadata": {
        "id": "R9shGC3O0drk"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "# modified.\n",
        "# res = requests.get(\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/previous_chapters.py\")\n",
        "res = requests.get(\"https://raw.githubusercontent.com/Aananda-giri/GPT2-Nepali/main/3.%20GPT2-Nepali/1.%20pre_training/previous_chapters.py\")\n",
        "with open('previous_chapters.py','w') as f:\n",
        "  f.write(res.text+pretrain_simple_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "2e3e68e0-2627-4c65-b4e7-1e0667e4f6fa",
      "metadata": {
        "id": "2e3e68e0-2627-4c65-b4e7-1e0667e4f6fa"
      },
      "outputs": [],
      "source": [
        "from gpt_model_code import (\n",
        "    generate,\n",
        "    # text_to_token_ids,\n",
        "    # token_ids_to_text\n",
        ")\n",
        "\n",
        "\n",
        "# token_ids = generate(\n",
        "#     model=model,\n",
        "#     idx=text_to_token_ids(input_text, tokenizer),\n",
        "#     max_new_tokens=35,\n",
        "#     context_size=BASE_CONFIG[\"context_length\"],\n",
        "#     eos_id=50256,\n",
        "# )\n",
        "#  = token_ids_to_text(token_ids, tokenizer)\n",
        "\n",
        "generated_text = generate(\n",
        "    model,\n",
        "    input_text,\n",
        "    tokenizer,\n",
        "    max_new_tokens=35,\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    top_p=None,  # New parameter for nucleus sampling\n",
        "    eos_id=None,\n",
        "    repetition_penalty=1.2,\n",
        "    penalize_len_below=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "NurJx0_u1b4z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "NurJx0_u1b4z",
        "outputId": "eacf8b05-6d73-49c1-a5bb-af808c3b96cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'तल दियीएको निर्देशन को उचित प्रतिक्रिया दिनुहोस।\\n\\n### प्रतिक्रिया:\\nथप रूपमा, इनपुटमा जनावरको सबैभन्दा प्रभावशाली विशेषताहरू मध्ये 5 सूचीबद्ध गर्नुहोस्\\n\\n### इनपुट:\\nजनावरः पेन्गुइन'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36e2fda5-f796-4954-8f72-1dd1123e3344",
      "metadata": {
        "id": "36e2fda5-f796-4954-8f72-1dd1123e3344"
      },
      "source": [
        "- Note that the `generate` function we used in previous chapters returns the combined input and output text, which was convenient in the previous section for creating legible text\n",
        "- To isolate the response, we can subtract the length of the instruction from the start of the `generated_text`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "ba4a55bf-a245-48d8-beda-2838a58fb5ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba4a55bf-a245-48d8-beda-2838a58fb5ba",
        "outputId": "842e29fb-132f-4963-a37f-182024588983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ः पेन्गुइन पेन्गुइनले निर्माण गरेको स्वचालित कारहरूको बारेमा । यो कार एक विशेष प्रकारको सुरक्षा कवच हो जसले कुनै पनि जनावर मानिसबीच सजिलै सम्पर्क गर्न सक्छ\n"
          ]
        }
      ],
      "source": [
        "response_text = (\n",
        "    generated_text[len(input_text):]\n",
        "    .replace(\"### प्रतिक्रिया:\", \"\")\n",
        "    .strip()\n",
        ")\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d44080b2-a4c5-4520-a797-549519f66a3e",
      "metadata": {
        "id": "d44080b2-a4c5-4520-a797-549519f66a3e"
      },
      "source": [
        "- As we can see, the model is not capable of following the instructions, yet; it creates a \"Response\" section but it simply repeats the original input sentence as well as the instruction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d27b9d-a942-4cf5-b797-848c5f01e723",
      "metadata": {
        "id": "70d27b9d-a942-4cf5-b797-848c5f01e723"
      },
      "source": [
        "## 7.6 Finetuning the LLM on instruction data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "314b2a39-88b4-44d8-8c85-1c5b0cd6cc4a",
      "metadata": {
        "id": "314b2a39-88b4-44d8-8c85-1c5b0cd6cc4a"
      },
      "source": [
        "- In this section, we finetune the model\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-5.webp?1\" width=500px>\n",
        "\n",
        "- Note that we can reuse all the loss calculation and training functions that we used in previous chapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "65444865-df87-4d98-9faf-875e1c4be860",
      "metadata": {
        "id": "65444865-df87-4d98-9faf-875e1c4be860"
      },
      "outputs": [],
      "source": [
        "from previous_chapters import (\n",
        "    calc_loss_loader,\n",
        "    train_model_simple\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00083059-aa41-4d37-8a17-1c72d1b1ca00",
      "metadata": {
        "id": "00083059-aa41-4d37-8a17-1c72d1b1ca00"
      },
      "source": [
        "- Let's calculate the initial training and validation set loss before we start training (as in previous chapters, the goal is to minimize the loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "d99fc6f8-63b2-43da-adbb-a7b6b92c8dd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d99fc6f8-63b2-43da-adbb-a7b6b92c8dd5",
        "outputId": "288eab97-7256-480a-e701-c25479309021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 5.673533344268799\n",
            "Validation loss: 5.408612632751465\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12a6da8f-15b3-42b0-a136-619b7a35c3e9",
      "metadata": {
        "id": "12a6da8f-15b3-42b0-a136-619b7a35c3e9"
      },
      "source": [
        "- Note that the training is a bit more expensive than in previous chapters since we are using a larger model (355 million instead of 124 million parameters)\n",
        "- The runtimes for various devices are shown for reference below (running this notebook on a compatible GPU device requires no changes to the code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db4b57fb-e689-4550-931c-6d34a932487c",
      "metadata": {
        "id": "db4b57fb-e689-4550-931c-6d34a932487c"
      },
      "source": [
        "<div style=\"text-align: left;\">\n",
        "    \n",
        "| Model              | Device                | Runtime for 2 Epochs |\n",
        "|--------------------|-----------------------|----------------------|\n",
        "| gpt2-medium (355M) | CPU (M3 MacBook Air)  | 15.78 minutes        |\n",
        "| gpt2-medium (355M) | GPU (M3 MacBook Air)  | 10.77 minutes        |\n",
        "| gpt2-medium (355M) | GPU (L4)              | 1.83 minutes         |\n",
        "| gpt2-medium (355M) | GPU (A100)            | 0.86 minutes         |\n",
        "| gpt2-small (124M)  | CPU (M3 MacBook Air)  | 5.74 minutes         |\n",
        "| gpt2-small (124M)  | GPU (M3 MacBook Air)  | 3.73 minutes         |\n",
        "| gpt2-small (124M)  | GPU (L4)              | 0.69 minutes         |\n",
        "| gpt2-small (124M)  | GPU (A100)            | 0.39 minutes         |\n",
        "\n",
        "</div>\n",
        "\n",
        "- I ran this notebook using the `\"gpt2-medium (355M)\"` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78bcf83a-1fff-4540-97c1-765c4016d5e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78bcf83a-1fff-4540-97c1-765c4016d5e3",
        "outputId": "dc639bec-1639-414a-ba2b-b7db3138ebfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 5.221, Val loss 5.014\n",
            "Ep 1 (Step 000005): Train loss 4.311, Val loss 4.435\n",
            "Ep 1 (Step 000010): Train loss 4.218, Val loss 4.275\n",
            "Ep 1 (Step 000015): Train loss 4.112, Val loss 4.245\n",
            "Ep 1 (Step 000020): Train loss 4.072, Val loss 4.171\n",
            "Ep 1 (Step 000025): Train loss 3.939, Val loss 4.131\n",
            "Ep 1 (Step 000030): Train loss 3.767, Val loss 4.102\n",
            "Ep 1 (Step 000035): Train loss 3.771, Val loss 4.060\n",
            "Ep 1 (Step 000040): Train loss 4.050, Val loss 4.030\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ise3wGjlB-iq",
      "metadata": {
        "id": "Ise3wGjlB-iq"
      },
      "source": [
        "- As we can see based on the outputs above, the model trains well, as we can tell based on the decreasing training loss and validation loss values\n",
        "- Furthermore, based on the response text printed after each epoch, we can see that the model correctly follows the instruction to convert the input sentence `'The chef cooks the meal every day.'` into passive voice `'The meal is cooked every day by the chef.'` (We will properly format and evaluate the responses in a later section)\n",
        "- Finally, let's take a look at the training and validation loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4acd368b-1403-4807-a218-9102e35bfdbb",
      "metadata": {
        "id": "4acd368b-1403-4807-a218-9102e35bfdbb"
      },
      "outputs": [],
      "source": [
        "from previous_chapters import plot_losses\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6777e0c4-d82c-46d8-84fb-1376c4f8bae0",
      "metadata": {
        "id": "6777e0c4-d82c-46d8-84fb-1376c4f8bae0"
      },
      "source": [
        "- As we can see, the loss decreases sharply at the beginning of the first epoch, which means the model starts learning quickly\n",
        "- We can see that slight overfitting sets in at around 1 training epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3",
      "metadata": {
        "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3"
      },
      "source": [
        "## 7.7 Extracting and saving responses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49",
      "metadata": {
        "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-6.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427",
      "metadata": {
        "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427"
      },
      "source": [
        "- In this section, we save the test set responses for scoring in the next section\n",
        "- We also save a copy of the model for future use\n",
        "- But first, let's take a brief look at the responses generated by the finetuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VQ2NZMbfucAc",
      "metadata": {
        "id": "VQ2NZMbfucAc"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ab64c1-586f-4939-8def-23feeb1b3599",
      "metadata": {
        "id": "49ab64c1-586f-4939-8def-23feeb1b3599"
      },
      "source": [
        "- As we can see based on the test set instructions, given responses, and the model's responses, the model performs relatively well\n",
        "- The answers to the first and last instructions are clearly correct\n",
        "- The second answer is close; the model answers with \"cumulus cloud\" instead of \"cumulonimbus\" (however, note that cumulus clouds can develop into cumulonimbus clouds, which are capable of producing thunderstorms)\n",
        "- Most importantly, we can see that model evaluation is not as straightforward as in the previous chapter, where we just had to calculate the percentage of correct spam/non-spam class labels to obtain the classification accuracy\n",
        "- In practice, instruction-finetuned LLMs such as chatbots are evaluated via multiple approaches\n",
        "  - short-answer and multiple choice benchmarks such as MMLU (\"Measuring Massive Multitask Language Understanding\", [https://arxiv.org/abs/2009.03300](https://arxiv.org/abs/2009.03300)), which test the knowledge of a model\n",
        "  - human preference comparison to other LLMs, such as LMSYS chatbot arena ([https://arena.lmsys.org](https://arena.lmsys.org))\n",
        "  - automated conversational benchmarks, where another LLM like GPT-4 is used to evaluate the responses, such as AlpacaEval ([https://tatsu-lab.github.io/alpaca_eval/](https://tatsu-lab.github.io/alpaca_eval/))\n",
        "\n",
        "- In the next section, we will use an approach similar to AlpacaEval and use another LLM to evaluate the responses of our model; however, we will use our own test set instead of using a publicly available benchmark dataset\n",
        "- For this, we add the model response to the `test_data` dictionary and save it as a `\"instruction-data-with-response.json\"` file for record-keeping so that we can load and analyze it in separate Python sessions if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-PNGKzY4snKP",
      "metadata": {
        "id": "-PNGKzY4snKP"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228d6fa7-d162-44c3-bef1-4013c027b155",
      "metadata": {
        "id": "228d6fa7-d162-44c3-bef1-4013c027b155"
      },
      "source": [
        "- Let's double-check one of the entries to see whether the responses have been added to the `test_data` dictionary correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u-AvCCMTnPSE",
      "metadata": {
        "id": "u-AvCCMTnPSE"
      },
      "outputs": [],
      "source": [
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('.')"
      ],
      "metadata": {
        "id": "9F7iiFhxE_ny"
      },
      "id": "9F7iiFhxE_ny",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c1b2f3f6-8569-405a-9db6-d47cba65608a",
      "metadata": {
        "id": "c1b2f3f6-8569-405a-9db6-d47cba65608a"
      },
      "source": [
        "- Finally, we also save the model in case we want to reuse it in the future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cBU0iHmVfOI",
      "metadata": {
        "id": "8cBU0iHmVfOI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")\n",
        "\n",
        "# Load model via\n",
        "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "obgoGI89dgPm",
      "metadata": {
        "id": "obgoGI89dgPm"
      },
      "source": [
        "## 7.8 Evaluating the finetuned LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "805b9d30-7336-499f-abb5-4a21be3129f5",
      "metadata": {
        "id": "805b9d30-7336-499f-abb5-4a21be3129f5"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-7.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68d2b9d3-b6ff-4533-a89d-7b66079b4fd1",
      "metadata": {
        "id": "68d2b9d3-b6ff-4533-a89d-7b66079b4fd1"
      },
      "source": [
        "- In this section, we automate the response evaluation of the finetuned LLM using another, larger LLM\n",
        "- In particular, we use an instruction-finetuned 8-billion-parameter Llama 3 model by Meta AI that can be run locally via ollama ([https://ollama.com](https://ollama.com))\n",
        "- (Alternatively, if you prefer using a more capable LLM like GPT-4 via the OpenAI API, please see the [llm-instruction-eval-openai.ipynb](../03_model-evaluation/llm-instruction-eval-openai.ipynb) notebook)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea427a30-36ba-44e3-bb1f-eb0d7008d6e9",
      "metadata": {
        "id": "ea427a30-36ba-44e3-bb1f-eb0d7008d6e9"
      },
      "source": [
        "- Ollama is an application to run LLMs efficiently\n",
        "- It is a wrapper around llama.cpp ([https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)), which implements LLMs in pure C/C++ to maximize efficiency\n",
        "- Note that it is a tool for using LLMs to generate text (inference), not training or finetuning LLMs\n",
        "- Before running the code below, install ollama by visiting [https://ollama.com](https://ollama.com) and following the instructions (for instance, clicking on the \"Download\" button and downloading the ollama application for your operating system)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747a2fc7-282d-47ec-a987-ed0a23ed6822",
      "metadata": {
        "id": "747a2fc7-282d-47ec-a987-ed0a23ed6822"
      },
      "source": [
        "- For macOS and Windows users, click on the ollama application you downloaded; if it prompts you to install the command line usage, say \"yes\"\n",
        "- Linux users can use the installation command provided on the ollama website\n",
        "\n",
        "- In general, before we can use ollama from the command line, we have to either start the ollama application or run `ollama serve` in a separate terminal\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/ollama-run.webp?1\" width=700px>\n",
        "\n",
        "\n",
        "- With the ollama application or `ollama serve` running in a different terminal, on the command line, execute the following command to try out the 8-billion-parameter Llama 3 model (the model, which takes up 4.7 GB of storage space, will be automatically downloaded the first time you execute this command)\n",
        "\n",
        "```bash\n",
        "# 8B model\n",
        "ollama run llama3\n",
        "```\n",
        "\n",
        "\n",
        "The output looks like as follows\n",
        "\n",
        "```\n",
        "$ ollama run llama3\n",
        "pulling manifest\n",
        "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB\n",
        "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB\n",
        "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B\n",
        "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B\n",
        "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B\n",
        "verifying sha256 digest\n",
        "writing manifest\n",
        "removing any unused layers\n",
        "success\n",
        "```\n",
        "\n",
        "- Note that `llama3` refers to the instruction finetuned 8-billion-parameter Llama 3 model\n",
        "\n",
        "- Using ollama with the `\"llama3\"` model (a 8B parameter model) requires 16 GB of RAM; if this is not supported by your machine, you can try the smaller model, such as the 3.8B parameter phi-3 model by setting `model = \"phi-3\"`, which only requires 8 GB of RAM\n",
        "\n",
        "- Alternatively, you can also use the larger 70-billion-parameter Llama 3 model, if your machine supports it, by replacing `llama3` with `llama3:70b`\n",
        "\n",
        "- After the download has been completed, you will see a command line prompt that allows you to chat with the model\n",
        "\n",
        "- Try a prompt like \"What do llamas eat?\", which should return an output similar to the following\n",
        "\n",
        "```\n",
        ">>> What do llamas eat?\n",
        "Llamas are ruminant animals, which means they have a four-chambered\n",
        "stomach and eat plants that are high in fiber. In the wild, llamas\n",
        "typically feed on:\n",
        "1. Grasses: They love to graze on various types of grasses, including tall\n",
        "grasses, wheat, oats, and barley.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b7b341c-ba0e-40bb-a52c-cb328bbd1fe4",
      "metadata": {
        "id": "7b7b341c-ba0e-40bb-a52c-cb328bbd1fe4"
      },
      "source": [
        "- You can end this session using the input `/bye`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faaf3e02-8ca0-4edf-be23-60625a5b14e3",
      "metadata": {
        "id": "faaf3e02-8ca0-4edf-be23-60625a5b14e3"
      },
      "source": [
        "- The following code checks whether the ollama session is running correctly before proceeding to use ollama to evaluate the test set responses we generated in the previous section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "026e8570-071e-48a2-aa38-64d7be35f288",
      "metadata": {
        "id": "026e8570-071e-48a2-aa38-64d7be35f288"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter([\"name\"]):\n",
        "        if process_name in proc.info[\"name\"]:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "\n",
        "ollama_running = check_if_running(\"ollama\")\n",
        "\n",
        "if not ollama_running:\n",
        "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
        "print(\"Ollama running:\", check_if_running(\"ollama\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0",
      "metadata": {
        "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0"
      },
      "outputs": [],
      "source": [
        "# This cell is optional; it allows you to restart the notebook\n",
        "# and only run section 7.7 without rerunning any of the previous code\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "file_path = \"instruction-data-with-response.json\"\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    test_data = json.load(file)\n",
        "\n",
        "\n",
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3464705-d026-4594-977f-fb357e51c3a9",
      "metadata": {
        "id": "b3464705-d026-4594-977f-fb357e51c3a9"
      },
      "source": [
        "- Now, an alternative way to the `ollama run` command we used earlier to interact with the model is via its REST API in Python via the following function\n",
        "- Before you run the next cells in this notebook, make sure that ollama is still running (the previous code cells should print `\"Ollama running: True\"`)\n",
        "- Next, run the following code cell to query the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ae0e10-2b28-42ce-8ea2-d9366a58088f",
      "metadata": {
        "id": "e3ae0e10-2b28-42ce-8ea2-d9366a58088f"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "def query_model(\n",
        "    prompt,\n",
        "    model=\"llama3\",\n",
        "    url=\"http://localhost:11434/api/chat\"\n",
        "):\n",
        "    # Create the data payload as a dictionary\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {     # Settings below are required for deterministic responses\n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
        "    payload = json.dumps(data).encode(\"utf-8\")\n",
        "\n",
        "    # Create a request object, setting the method to POST and adding necessary headers\n",
        "    request = urllib.request.Request(\n",
        "        url,\n",
        "        data=payload,\n",
        "        method=\"POST\"\n",
        "    )\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "\n",
        "    # Send the request and capture the response\n",
        "    response_data = \"\"\n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        # Read and decode the response\n",
        "        while True:\n",
        "            line = response.readline().decode(\"utf-8\")\n",
        "            if not line:\n",
        "                break\n",
        "            response_json = json.loads(line)\n",
        "            response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data\n",
        "\n",
        "\n",
        "model = \"llama3\"\n",
        "result = query_model(\"What do Llamas eat?\", model)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "207ae28f-0f8c-4fda-aeef-e7e3046249cc",
      "metadata": {
        "id": "207ae28f-0f8c-4fda-aeef-e7e3046249cc"
      },
      "source": [
        "- Now, using the `query_model` function we defined above, we can evaluate the responses of our finetuned model; let's try it out on the first 3 test set responses we looked at in a previous section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b839d4-064d-4178-b2d7-01691b452e5e",
      "metadata": {
        "id": "86b839d4-064d-4178-b2d7-01691b452e5e"
      },
      "outputs": [],
      "source": [
        "for entry in test_data[:3]:\n",
        "    prompt = (\n",
        "        f\"Given the input `{format_input(entry)}` \"\n",
        "        f\"and correct output `{entry['output']}`, \"\n",
        "        f\"score the model response `{entry['model_response']}`\"\n",
        "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "    )\n",
        "    print(\"\\nDataset response:\")\n",
        "    print(\">>\", entry['output'])\n",
        "    print(\"\\nModel response:\")\n",
        "    print(\">>\", entry[\"model_response\"])\n",
        "    print(\"\\nScore:\")\n",
        "    print(\">>\", query_model(prompt))\n",
        "    print(\"\\n-------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b114fd65-9cfb-45f6-ab74-8331da136bf3",
      "metadata": {
        "id": "b114fd65-9cfb-45f6-ab74-8331da136bf3"
      },
      "source": [
        "- As we can see, the Llama 3 model provides a reasonable evaluation and also gives partial points if a model is not entirely correct, as we can see based on the \"cumulus cloud\" answer\n",
        "- Note that the previous prompt returns very verbose evaluations; we can tweak the prompt to generate integer responses in the range between 0 and 100 (where 100 is best) to calculate an average score for our model\n",
        "- The evaluation of the 110 entries in the test set takes about 1 minute on an M3 MacBook Air laptop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d7bca69-97c4-47a5-9aa0-32f116fa37eb",
      "metadata": {
        "id": "9d7bca69-97c4-47a5-9aa0-32f116fa37eb"
      },
      "outputs": [],
      "source": [
        "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
        "    scores = []\n",
        "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
        "        prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and correct output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry[json_key]}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "            f\"Respond with the integer number only.\"\n",
        "        )\n",
        "        score = query_model(prompt, model)\n",
        "        try:\n",
        "            scores.append(int(score))\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert score: {score}\")\n",
        "            continue\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "scores = generate_model_scores(test_data, \"model_response\")\n",
        "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
        "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2",
      "metadata": {
        "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2"
      },
      "source": [
        "- Our model achieves an average score of above 50, which we can use as a reference point to compare the model to other models or to try out other training settings that may improve the model\n",
        "- Note that ollama is not fully deterministic across operating systems (as of this writing), so the numbers you are getting might slightly differ from the ones shown above"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94",
      "metadata": {
        "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94"
      },
      "source": [
        "- For reference, the original\n",
        "  - Llama 3 8B base model achieves a score of 58.51\n",
        "  - Llama 3 8B instruct model achieves a score of 82.65"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "412d7325-284a-446c-92a1-5aa8acc52dee",
      "metadata": {
        "id": "412d7325-284a-446c-92a1-5aa8acc52dee"
      },
      "source": [
        "## 7.9 Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tIbNMluCDjVM",
      "metadata": {
        "id": "tIbNMluCDjVM"
      },
      "source": [
        "### 7.9.1 What's next\n",
        "\n",
        "- This marks the final chapter of this book\n",
        "- We covered the major steps of the LLM development cycle: implementing an LLM architecture, pretraining an LLM, and finetuning it\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/final-overview.webp?1\" width=500px>\n",
        "\n",
        "- An optional step that is sometimes followed after instruction finetuning, as described in this chapter, is preference finetuning\n",
        "- Preference finetuning process can be particularly useful for customizing a model to better align with specific user preferences; see the [../04_preference-tuning-with-dpo](../04_preference-tuning-with-dpo) folder if you are interested in this\n",
        "\n",
        "- This GitHub repository also contains a large selection of additional bonus material you may enjoy; for more information, please see the [Bonus Material](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material) section on this repository's README page\n",
        "\n",
        "### 7.9.2 Staying up to date in a fast-moving field\n",
        "\n",
        "- No code in this section\n",
        "\n",
        "### 7.9.3 Final words\n",
        "\n",
        "- I hope you enjoyed this journey of implementing an LLM from the ground up and coding the pretraining and finetuning functions\n",
        "- In my opinion, implementing an LLM from scratch is the best way to understand how LLMs work; I hope you gained a better understanding through this approach\n",
        "- While this book serves educational purposes, you may be interested in using different and more powerful LLMs for real-world applications\n",
        "  - For this, you may consider popular tools such as axolotl ([https://github.com/OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)) or LitGPT ([https://github.com/Lightning-AI/litgpt](https://github.com/Lightning-AI/litgpt)), which I help developing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9853e7f-a81a-4806-9728-be1690807185",
      "metadata": {
        "id": "f9853e7f-a81a-4806-9728-be1690807185"
      },
      "source": [
        "## Summary and takeaways\n",
        "\n",
        "- See the [./gpt_instruction_finetuning.py](./gpt_instruction_finetuning.py) script, a self-contained script for classification finetuning\n",
        "- [./ollama_evaluate.py](./ollama_evaluate.py) is a standalone script based on section 7.8 that evaluates a JSON file containing \"output\" and \"response\" keys via Ollama and Llama 3\n",
        "- The [./load-finetuned-model.ipynb](./load-finetuned-model.ipynb) notebook illustrates how to load the finetuned model in a new session\n",
        "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9cc51ec-e06c-4470-b626-48401a037851",
      "metadata": {
        "id": "b9cc51ec-e06c-4470-b626-48401a037851"
      },
      "source": [
        "## What's next?\n",
        "\n",
        "- Congrats on completing the book; in case you are looking for additional resources, I added several bonus sections to this GitHub repository that you might find interesting\n",
        "- The complete list of bonus materials can be viewed in the main README's [Bonus Material](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material) section\n",
        "- To highlight a few of my favorites:\n",
        "  1. [Direct Preference Optimization (DPO) for LLM Alignment (From Scratch)](../04_preference-tuning-with-dpo/dpo-from-scratch.ipynb) implements a popular preference tuning mechanism to align the model from this chapter more closely with human preferences\n",
        "  2. [Llama 3.2 From Scratch (A Standalone Notebook)](../../ch05/07_gpt_to_llama/standalone-llama32.ipynb), a from-scratch implementation of Meta AI's popular Llama 3.2, including loading the official pretrained weights; if you are up to some additional experiments, you can replace the `GPTModel` model in each of the chapters with the `Llama3Model` class (it should work as a 1:1 replacement)\n",
        "  3. [Converting GPT to Llama](../../ch05/07_gpt_to_llama) contains code with step-by-step guides that explain the differences between GPT-2 and the various Llama models\n",
        "  4. [Understanding the Difference Between Embedding Layers and Linear Layers](../../ch02/03_bonus_embedding-vs-matmul/embeddings-and-linear-layers.ipynb) is a conceptual explanation illustrating that the `Embedding` layer in PyTorch, which we use at the input stage of an LLM, is mathematically equivalent to a linear layer applied to one-hot encoded data\n",
        "- Happy further reading!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Done\n",
        "- [X] Remove english dataset from wiseyak by (using langid)\n",
        "\n",
        "# Todo\n",
        "\n",
        "- [ ] More data\n",
        "- [ ] more epochs\n",
        "- [ ] save to hub\n"
      ],
      "metadata": {
        "id": "LFCX0UwNg8qW"
      },
      "id": "LFCX0UwNg8qW"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rUUOFiYVg7qM"
      },
      "id": "rUUOFiYVg7qM",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12aa86ab7ccd4d04ae05145cee2ace25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edd8c72bc25b42059f134ecc3b302c44",
              "IPY_MODEL_fc72e11e7fc740e8a8bcd325224eb1f7",
              "IPY_MODEL_c6f4679bc08d48b281a4a49fa557f290"
            ],
            "layout": "IPY_MODEL_6b76b45fbb3e4abdb271e83429d80071"
          }
        },
        "edd8c72bc25b42059f134ecc3b302c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b40bef8d56fa413aa805fb7f16e53232",
            "placeholder": "​",
            "style": "IPY_MODEL_a4c6e024e4e84ab6b923b17dd49f2063",
            "value": "README.md: 100%"
          }
        },
        "fc72e11e7fc740e8a8bcd325224eb1f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc80e439e99440a9f837768be4d6e28",
            "max": 744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f070fd4abb6c417799af732624467359",
            "value": 744
          }
        },
        "c6f4679bc08d48b281a4a49fa557f290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e430de5ac2b2480a8a33fabec7149caa",
            "placeholder": "​",
            "style": "IPY_MODEL_ffff2e5683624bf1a29ce248544662b4",
            "value": " 744/744 [00:00&lt;00:00, 15.5kB/s]"
          }
        },
        "6b76b45fbb3e4abdb271e83429d80071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40bef8d56fa413aa805fb7f16e53232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4c6e024e4e84ab6b923b17dd49f2063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cc80e439e99440a9f837768be4d6e28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f070fd4abb6c417799af732624467359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e430de5ac2b2480a8a33fabec7149caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffff2e5683624bf1a29ce248544662b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f70b9835b1fd42a2837cf76c894661bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_467484aec7e3487aa03c28bea096c903",
              "IPY_MODEL_382e407c5e2640b0bcfa597727508c4d",
              "IPY_MODEL_75448f76e86a417e85b2fa7f40c6589f"
            ],
            "layout": "IPY_MODEL_8561f0070e304dc5b8956829f664a329"
          }
        },
        "467484aec7e3487aa03c28bea096c903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdf3ceb14eeb4e27856fe79c103332ae",
            "placeholder": "​",
            "style": "IPY_MODEL_809231b736d4417e941ab684f8f483cc",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "382e407c5e2640b0bcfa597727508c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87be4eec65da4e009c2061f847ad6da1",
            "max": 71364603,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc5ee43429894db1ae3afbc426368ffc",
            "value": 71364603
          }
        },
        "75448f76e86a417e85b2fa7f40c6589f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d252bea60e47beba7a19f5e73b7bcb",
            "placeholder": "​",
            "style": "IPY_MODEL_f8f4054069e04f21aeb76583fa985807",
            "value": " 71.4M/71.4M [00:01&lt;00:00, 59.8MB/s]"
          }
        },
        "8561f0070e304dc5b8956829f664a329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdf3ceb14eeb4e27856fe79c103332ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "809231b736d4417e941ab684f8f483cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87be4eec65da4e009c2061f847ad6da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc5ee43429894db1ae3afbc426368ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1d252bea60e47beba7a19f5e73b7bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8f4054069e04f21aeb76583fa985807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2762d9882bc445bf92c15dce0b3bbb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9b99e8a7c64462dbe6503f542691718",
              "IPY_MODEL_0c5fe1e2c485414e86005eebbb44b770",
              "IPY_MODEL_9d7e756e12a748ea98de28870300857d"
            ],
            "layout": "IPY_MODEL_e59c6b8df3464660ac383523e08b9f91"
          }
        },
        "d9b99e8a7c64462dbe6503f542691718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ac73bd164940d6aa6f1fbf7c7841b4",
            "placeholder": "​",
            "style": "IPY_MODEL_2e1751fb411e4b67a66afb7cca604f16",
            "value": "Generating train split: 100%"
          }
        },
        "0c5fe1e2c485414e86005eebbb44b770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c076897308c403081c8a793dee2a419",
            "max": 113751,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2369a38eb6444b49b0f5bf0188e8249d",
            "value": 113751
          }
        },
        "9d7e756e12a748ea98de28870300857d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21875bc5b7f4479bb95dc7589e5906ff",
            "placeholder": "​",
            "style": "IPY_MODEL_91351da4c2b54246aed65121da1f253f",
            "value": " 113751/113751 [00:01&lt;00:00, 93465.13 examples/s]"
          }
        },
        "e59c6b8df3464660ac383523e08b9f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ac73bd164940d6aa6f1fbf7c7841b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e1751fb411e4b67a66afb7cca604f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c076897308c403081c8a793dee2a419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2369a38eb6444b49b0f5bf0188e8249d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21875bc5b7f4479bb95dc7589e5906ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91351da4c2b54246aed65121da1f253f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78dd1bf6d63344a294395ece64b58523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5a4d219898c420e89ba131c913690e4",
              "IPY_MODEL_046c20ee19054545a7da0c2155ccc655",
              "IPY_MODEL_4708e90d116748b2ada25c038626aeea"
            ],
            "layout": "IPY_MODEL_43435e825a3542a5a1967bd2fa771b5a"
          }
        },
        "c5a4d219898c420e89ba131c913690e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a25c7dc72fda44a5b26fd585d516eee4",
            "placeholder": "​",
            "style": "IPY_MODEL_d7bb83a9396e4c9f8642c6b845764966",
            "value": ""
          }
        },
        "046c20ee19054545a7da0c2155ccc655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_115593a1493e4ff2877a71ba027b9153",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6414a951d7945499da92576e2dc08d5",
            "value": 0
          }
        },
        "4708e90d116748b2ada25c038626aeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5951e69c91f94ca38074e88b70b6022c",
            "placeholder": "​",
            "style": "IPY_MODEL_5522f6e20e704a24a63c8b2fe57cb111",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "43435e825a3542a5a1967bd2fa771b5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a25c7dc72fda44a5b26fd585d516eee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7bb83a9396e4c9f8642c6b845764966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "115593a1493e4ff2877a71ba027b9153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c6414a951d7945499da92576e2dc08d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5951e69c91f94ca38074e88b70b6022c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5522f6e20e704a24a63c8b2fe57cb111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83e7f4df09c947bba4651a57e245caec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59b7603d166747a6b4ec5c8b2663615f",
              "IPY_MODEL_7840bb35972d49d7aabecc3679310a39",
              "IPY_MODEL_dbefb28230734a9396970295b8aa40c1"
            ],
            "layout": "IPY_MODEL_16a535ce3a0540d38427b848d7d9f724"
          }
        },
        "59b7603d166747a6b4ec5c8b2663615f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5a7d47d2c484afda438f4d30e384353",
            "placeholder": "​",
            "style": "IPY_MODEL_e6d5b704defd43109d8e504d405ec770",
            "value": "config.json: 100%"
          }
        },
        "7840bb35972d49d7aabecc3679310a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c03289a162f4665ad9da7eed76a5629",
            "max": 196,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e000427fcdbc46fa9c2f8ec9765f6a24",
            "value": 196
          }
        },
        "dbefb28230734a9396970295b8aa40c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f68fdc697a24efd8247482209190015",
            "placeholder": "​",
            "style": "IPY_MODEL_381ee4c0cc554816a066d3ee3c8d21ea",
            "value": " 196/196 [00:00&lt;00:00, 18.7kB/s]"
          }
        },
        "16a535ce3a0540d38427b848d7d9f724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a7d47d2c484afda438f4d30e384353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d5b704defd43109d8e504d405ec770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c03289a162f4665ad9da7eed76a5629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e000427fcdbc46fa9c2f8ec9765f6a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f68fdc697a24efd8247482209190015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "381ee4c0cc554816a066d3ee3c8d21ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "902d74e63c904d409d9d38177cd98611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0dd48dd4af84d108816da0f859a9437",
              "IPY_MODEL_5dd7c59ad9d0400ca307f0a94bdd5054",
              "IPY_MODEL_28b6460138ab483f8739217089037bf3"
            ],
            "layout": "IPY_MODEL_71e3df1690e94ef8a40e10c5ddbf55a7"
          }
        },
        "f0dd48dd4af84d108816da0f859a9437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ed7c352b2c46c4ae7fcc9c4912a9c5",
            "placeholder": "​",
            "style": "IPY_MODEL_ca3d854bc60b44fb98916cfba03ff82e",
            "value": "model.safetensors: 100%"
          }
        },
        "5dd7c59ad9d0400ca307f0a94bdd5054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52e57167237411683e53f80b7111d37",
            "max": 661486448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f6ec3d692f943e4843b01c93d3d85b4",
            "value": 661486448
          }
        },
        "28b6460138ab483f8739217089037bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb6e39930e854ebe857f6854c3ac91cf",
            "placeholder": "​",
            "style": "IPY_MODEL_a0de7080f8d84025a8c1c6c8f80f4f13",
            "value": " 661M/661M [00:10&lt;00:00, 54.7MB/s]"
          }
        },
        "71e3df1690e94ef8a40e10c5ddbf55a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ed7c352b2c46c4ae7fcc9c4912a9c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3d854bc60b44fb98916cfba03ff82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f52e57167237411683e53f80b7111d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f6ec3d692f943e4843b01c93d3d85b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb6e39930e854ebe857f6854c3ac91cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0de7080f8d84025a8c1c6c8f80f4f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}