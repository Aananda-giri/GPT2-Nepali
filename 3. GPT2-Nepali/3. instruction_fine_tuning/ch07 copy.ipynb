{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "12e91914-5f51-43fa-b65b-625e73b4d17b",
      "metadata": {
        "id": "12e91914-5f51-43fa-b65b-625e73b4d17b"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
        "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp?1\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf",
      "metadata": {
        "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf"
      },
      "source": [
        "# Chapter 7: Finetuning To Follow Instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rb34vm442-rD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb34vm442-rD",
        "outputId": "1c319230-f3b1-4dbc-cd88-4c4388aad0ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
        "outputId": "9dff9f78-45ee-4d85-a8d5-ea590bc288f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "matplotlib version: 3.10.0\n",
            "tiktoken version: 0.8.0\n",
            "torch version: 2.5.1+cu124\n",
            "tqdm version: 4.67.1\n",
            "tensorflow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "\n",
        "pkgs = [\n",
        "    \"matplotlib\",  # Plotting library\n",
        "    \"tiktoken\",    # Tokenizer\n",
        "    \"torch\",       # Deep learning library\n",
        "    \"tqdm\",        # Progress bar\n",
        "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
        "]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "264fca98-2f9a-4193-b435-2abfa3b4142f",
      "metadata": {
        "id": "264fca98-2f9a-4193-b435-2abfa3b4142f"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/overview.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813",
      "metadata": {
        "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813"
      },
      "source": [
        "## 7.1 Introduction to instruction finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab",
      "metadata": {
        "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab"
      },
      "source": [
        "- In chapter 5, we saw that pretraining an LLM involves a training procedure where it learns to generate one word at a time\n",
        "- Hence, a pretrained LLM is good at text completion, but it is not good at following instructions\n",
        "- In this chapter, we teach the LLM to follow instructions better"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18dc0535-0904-44ed-beaf-9b678292ef35",
      "metadata": {
        "id": "18dc0535-0904-44ed-beaf-9b678292ef35"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/instruction-following.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8",
      "metadata": {
        "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8"
      },
      "source": [
        "- The topics covered in this chapter are summarized in the figure below\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-1.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86",
      "metadata": {
        "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86"
      },
      "source": [
        "## 7.2 Preparing a dataset for supervised instruction finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8b34ff8-619f-4e89-bd03-ce513269760d",
      "metadata": {
        "id": "f8b34ff8-619f-4e89-bd03-ce513269760d"
      },
      "source": [
        "- We will work with an instruction dataset I prepared for this chapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "npMdH0Zjho2G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "npMdH0Zjho2G",
        "outputId": "0df26eeb-75e4-4aa8-b178-52385a0d6f23"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'नुवाकोटको तारकेश्वर गाउँपालिका ५ को बिर्ता व्यथा त्यो जिल्लाका अन्यत्रभन्दा बिल्कुल फरक छ । जिल्लाका राजनीतिकर्मी र भूमि अभियन्ताका अनुसार नुवाकोटमा सबैभन्दा बढी बिर्तापीडित किसान यही वडामा बस्छन् । जिल्लाभरिमै बिर्ता समस्याले सबैभन्दा गाँजेको यस वडाका जमिन जोत्ने किसानलाई शताब्दीऔंदेखि सरकारी अड्डाले अल्झाइरहेको छ ।'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Probably should `clean_data(new_crawled_data)` before merging `new_crawled_data.csv` and previous`cleaned_data.csv`\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class CleanData:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        # return text\n",
        "    # Example of removing HTML tags\n",
        "    def clean_html(self, text):\n",
        "        '''\n",
        "        # HTML Tag Removal:\n",
        "        * removes html tags like: <h1>\n",
        "        * Removes css or js code inside <style> and <script> tags\n",
        "        '''\n",
        "        soup = BeautifulSoup(text, \"lxml\")\n",
        "\n",
        "        # Remove all <script> and <style> tags\n",
        "        for script_or_style in soup(['script', 'style']):\n",
        "            script_or_style.decompose()\n",
        "\n",
        "        # Get text from the modified HTML\n",
        "        text = soup.get_text(separator=' ', strip=True)\n",
        "        # print(text)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def convert_to_devanagari_digits(self, input_string):\n",
        "        # Function to convert 0-9 to ० - ९\n",
        "        # i.e. Mapping of ASCII digits to Devanagari digits\n",
        "        devanagari_digits = {\n",
        "            '0': '०',\n",
        "            '1': '१',\n",
        "            '2': '२',\n",
        "            '3': '३',\n",
        "            '4': '४',\n",
        "            '5': '५',\n",
        "            '6': '६',\n",
        "            '7': '७',\n",
        "            '8': '८',\n",
        "            '9': '९'\n",
        "        }\n",
        "        # Convert each digit in the input string\n",
        "        result = ''.join(devanagari_digits[char] if char in devanagari_digits else char for char in input_string)\n",
        "        return result\n",
        "\n",
        "\n",
        "    def remove_non_devanagari_characters(self, text, keep_special_characters=True):\n",
        "        '''\n",
        "            # Function to find nepali sequences.\n",
        "            * keep punctuations if they occur between devanagari characters.\n",
        "            * Remove punctuation if previous character is not devanagari.\n",
        "            # Examples\n",
        "            texts = [\n",
        "                \"उनले दुहेको दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे। \\\"hi there\\\". what is your name? उनले दुहेको दूध\",\n",
        "                \"\\\"hi there. \\\"उनले दुहेको\\\" दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे। hi there. what is your name? उनले दुहेको दूध\\\"\",\n",
        "                \"name? उनले दुहेको दूध\\\"\"    #output: (last quatation, name?) should be ignored\n",
        "                ]\n",
        "\n",
        "            for text in texts:\n",
        "                removed = remove_non_devanagari_characters(text)\n",
        "                print(f'text: {text}, \\nclen: {removed}\\n\\n')\n",
        "\n",
        "\n",
        "            # output\n",
        "            text: उनले दुहेको दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे। \"hi there\". what is your name? उनले दुहेको दूध,\n",
        "            clen: उनले दुहेको दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे।             उनले दुहेको दूध\n",
        "\n",
        "\n",
        "            text: \"hi there. \"उनले दुहेको\" दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे। hi there. what is your name? उनले दुहेको दूध\",\n",
        "            clen:    \"उनले दुहेको दूध बेच्नका लागि बजार असाध्यै सानो थियो त्यसैले उनले चीज बनाउने विचार गरे।             उनले दुहेको दूध\"\n",
        "\n",
        "\n",
        "            text: name? उनले दुहेको दूध\",\n",
        "            clen:  उनले दुहेको दूध\"\n",
        "        '''\n",
        "        def is_devanagari(char):\n",
        "            pattern=r'[ऀ-ॿ]'\n",
        "            return bool(re.match(pattern, char))\n",
        "\n",
        "        if not keep_special_characters:\n",
        "            return re.sub(r\"[^ऀ-ॿ ]\", \" \", text)\n",
        "\n",
        "        sequences = []\n",
        "        sequence = ''\n",
        "        punctuation_symbols = string.punctuation    # '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
        "        prefix_punctuations = '\\\"\\'(<[{'\n",
        "        index=0\n",
        "        while index < len(text):\n",
        "            char = text[index]\n",
        "            if is_devanagari(char) or char == ' ':\n",
        "                # Character is devanagari\n",
        "                sequence += char\n",
        "            elif char in punctuation_symbols:\n",
        "                # Character is punctuation\n",
        "                if sequence != '':\n",
        "                    if (len(text) > index+1) and not is_devanagari(text[index+1]):\n",
        "                        # e.g. गरे। \"hi there\" : skip quotation before hi\n",
        "                        pass\n",
        "                    else:\n",
        "                        sequence += char    # Sequence is no empty. i.e. previous char/sequence was devanagari otherwise ignore  punctuation\n",
        "                elif (len(text) > index+1) and is_devanagari(text[index+1]):\n",
        "                    # preserve prefix punctuations in devanagari. e.g. \"\"\"there. \\\"उनले \"\": preserve double-quotation before उनले\n",
        "                    sequence = char + text[index+1]\n",
        "                    index += 1  # another 1 is added at the end\n",
        "            else:\n",
        "                if sequence:\n",
        "                    sequences.append(sequence)\n",
        "                    sequence = ''   # Reset sequence\n",
        "            index += 1\n",
        "\n",
        "            # print(f'{sequences}\\n{sequence}\\n{char}{is_devanagari(char)}\\n\\n')\n",
        "        if sequence:    # last sequence\n",
        "            sequences.append(sequence)\n",
        "        return ' '.join(sequences)\n",
        "        # Example of using regex for special character removal\n",
        "\n",
        "    def normalize_data(self, text):\n",
        "      '''\n",
        "        * Standerize special characters\n",
        "        * e.g. convert different types of quotes to standard quotes\n",
        "      '''\n",
        "      characters_to_replace = {\n",
        "        '₹': 'रु',\n",
        "        'ʻ': \"'\",\n",
        "        'ː': ':',\n",
        "        '？': '?',\n",
        "        '‟': '\"',\n",
        "        '“' : '\"',\n",
        "        '”': '\"',\n",
        "        '`': \"'\",\n",
        "        '৷': '।',\n",
        "        'ˈ': \"'\",\n",
        "        '՛': \"'\",\n",
        "        'ǃ': '!',\n",
        "        '（': '(',\n",
        "        '：': ':',\n",
        "        'ˍ': '_',\n",
        "        '﹣': '-',\n",
        "        '״': '\"',\n",
        "        'ꞌ': \"'\",\n",
        "        '₋': '-',\n",
        "        '％': '%',\n",
        "        '꞉': ':',\n",
        "        '‵': \"'\"\n",
        "      }\n",
        "      # Replace each character in the dictionary with its corresponding standard character\n",
        "      for char, replacement in characters_to_replace.items():\n",
        "          text = text.replace(char, replacement)\n",
        "\n",
        "      return text\n",
        "\n",
        "    def clean_data(self, text):\n",
        "        # Remove HTML tags\n",
        "        text = self.clean_html(text)\n",
        "\n",
        "        # Normalize some characters\n",
        "        text = self.normalize_data(text)\n",
        "\n",
        "        # Convert 0-9 to ० - ९\n",
        "        text = self.convert_to_devanagari_digits(text)\n",
        "\n",
        "        text = self.remove_non_devanagari_characters(text, keep_special_characters=True)\n",
        "        # text = text.lower() # No lower characters in devanagari\n",
        "\n",
        "        # Replace one or more spaces with a single space\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        return text\n",
        "\n",
        "data_cleaner = CleanData()\n",
        "data_cleaner.clean_data('hi नुवाकोटको there तारकेश्वर गाउँपालिका–५ को बिर्ता–व्यथा त्यो जिल्लाका अन्यत्रभन्दा बिल्कुल फरक छ । जिल्लाका राजनीतिकर्मी र भूमि अभियन्ताका अनुसार, नुवाकोटमा सबैभन्दा बढी बिर्तापीडित किसान यही वडामा बस्छन् । जिल्लाभरिमै बिर्ता समस्याले सबैभन्दा गाँजेको यस वडाका जमिन जोत्ने किसानलाई शताब्दीऔंदेखि सरकारी अड्डाले अल्झाइरहेको छ ।')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "zVcbmq25hbcG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456,
          "referenced_widgets": [
            "73890def4a65469f9843a58ec75e3d91",
            "ea22ec18d99b4aa7aebc5c4fed7a177f",
            "3f11504bcc0646ee96ef18d833e25692",
            "6254d34f8fc74b0caec6600a4e31ded4",
            "cc5dcd93fc71469687c63eb112bfcae0",
            "e10fc7b48e334def92df6aa38433fbf0",
            "ab74f8f4a3fd4bd48d4769bf31f45bcf",
            "19eec44a2e774809a8a21f81e477357b",
            "505100a9618b4d9e9455b04a9a7e53b3",
            "53997b1438324aafa09243fea116a6bc",
            "033a21ee3ce04a0b8dcfed1d156b0c6e",
            "d95197cfa8b441a1974fd9f8a2d8c5a3",
            "a733e306c8d7454b978dcb4d6f283e72",
            "13836d0d50a84f9781f8eac797108dd4",
            "5e2ee6f7e3ed49ebaaa2db1375098a99",
            "62ee1e5991df4758b35823f3adc5ccf4",
            "58e0005fd18a41e99bbf591943819b5d",
            "53ab715769364edea60cdf235fc174ee",
            "4d51f1dda0b14d04bd84371e206b5735",
            "8b19f68e6d5145ceac263e0fd0d3bcf4",
            "56073cd05332458ebe7a31f5cd45883e",
            "3c379942a4a747f6bfe98a0e04b79566",
            "931d2a02a3044ed2beaf6e556df2904f",
            "c0278cab6425484db469ea46e2005896",
            "4a399b40db8f486795c217ee54a5630a",
            "efd8d741e52144ae85ea7c3843d6a89f",
            "3a1d387c7ce9458ab5fc48b1474eee54",
            "ff5b51e53f964204ad46acaa4bb1eada",
            "6ea5308bc6d04a55ba2e978a50df6853",
            "65cbdc4dbb6c41509d0bf4720f13e11d",
            "945d587d7a424a21b0109acf79436001",
            "64df8ad77ee84b0ebd434d0497548b75",
            "4cde55c5fcc0437b8a239d6164333292"
          ]
        },
        "id": "zVcbmq25hbcG",
        "outputId": "6d7f33b3-9d7b-4dd3-a672-1dbea5863a8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m471.0/480.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73890def4a65469f9843a58ec75e3d91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/384 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d95197cfa8b441a1974fd9f8a2d8c5a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/18.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "931d2a02a3044ed2beaf6e556df2904f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/52005 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install datasets --quiet\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"Saugatkafley/alpaca-nepali-sft\")\n",
        "data = [d for d in ds['train']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4xbxHTkus5jI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xbxHTkus5jI",
        "outputId": "1453b148-eb26-401c-c30d-2001aff3a297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type: <class 'list'>, len:52005 \n",
            " sample: {'instruction': 'स्वस्थ रहन तीनवटा टिप्स दिनुहोस्।', 'input': '', 'output': '1. सन्तुलित आहार खानुहोस् र प्रशस्त फलफूल र तरकारीहरू समावेश गर्न निश्चित गर्नुहोस्।\\n2. आफ्नो शरीर सक्रिय र बलियो राख्न नियमित रूपमा व्यायाम गर्नुहोस्।\\n3. पर्याप्त निद्रा लिनुहोस् र एक सुत्ने तालिका कायम राख्नुहोस्।', 'id': 0}\n"
          ]
        }
      ],
      "source": [
        "print(f'type: {type(data)}, len:{len(data)} \\n sample: {data[0]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7af8176-4255-4e92-8c7d-998771733eb8",
      "metadata": {
        "id": "d7af8176-4255-4e92-8c7d-998771733eb8"
      },
      "source": [
        "- Each item in the `data` list we loaded from the JSON file above is a dictionary in the following form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "-LiuBMsHkzQV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LiuBMsHkzQV",
        "outputId": "c1ccf039-5e9d-49dc-d4bd-7f1324b1bba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example entry:\n",
            " {'instruction': 'यसलाई थप संक्षिप्त बनाउन निम्न वाक्य सम्पादन गर्नुहोस्।', 'input': 'पाँच मिनेटमा आइपुग्नु पर्ने बस समात्न उनी दौडिएर बस स्टपमा पुगे ।', 'output': 'पाँच मिनेटमा आइपुग्ने भन्दै उनी दौडिएर बस स्टपमा पुगे ।', 'id': 50}\n"
          ]
        }
      ],
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46",
      "metadata": {
        "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46"
      },
      "source": [
        "- Note that the `'input'` field can be empty:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "uFInFxDDk2Je",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFInFxDDk2Je",
        "outputId": "b8d0560f-419d-4baa-d13e-0144f4ad2ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Another example entry:\n",
            " {'instruction': 'निम्न प्रकारको खानाको स्वाद प्रोफाइल वर्णन गर्नुहोस्', 'input': 'जापानी', 'output': 'जापानी व्यञ्जन यसको सूक्ष्म र नाजुक स्वादहरू द्वारा विशेषता हो, नमकीन, मीठो, खट्टा, र उमामी स्वादहरूको संयोजनको विशेषता। यसले तिनीहरूको प्राकृतिक स्वादको संरक्षणमा ध्यान केन्द्रित गरेर ताजा सामग्रीहरू पनि प्रयोग गर्दछ।', 'id': 999}\n"
          ]
        }
      ],
      "source": [
        "print(\"Another example entry:\\n\", data[999])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f034799a-6575-45fd-98c9-9d1012d0fd58",
      "metadata": {
        "id": "f034799a-6575-45fd-98c9-9d1012d0fd58"
      },
      "source": [
        "- Instruction finetuning is often referred to as \"supervised instruction finetuning\" because it involves training a model on a dataset where the input-output pairs are explicitly provided\n",
        "- There are different ways to format the entries as inputs to the LLM; the figure below illustrates two example formats that were used for training the Alpaca (https://crfm.stanford.edu/2023/03/13/alpaca.html) and Phi-3 (https://arxiv.org/abs/2404.14219) LLMs, respectively"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10",
      "metadata": {
        "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/prompt-style.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6",
      "metadata": {
        "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6"
      },
      "source": [
        "- In this chapter, we use Alpaca-style prompt formatting, which was the original prompt template for instruction finetuning\n",
        "- Below, we format the input that we will pass as input to the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "Jhk37nnJnkBh",
      "metadata": {
        "id": "Jhk37nnJnkBh"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"तल दियीएको निर्देशन को उचित प्रतिक्रिया दिनुहोस।\"\n",
        "        f\"\\n\\n### प्रतिक्रिया:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### इनपुट:\\n{entry['input']}\" if entry[\"input\"] and '<noinput>' not in entry['input'] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6",
      "metadata": {
        "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6"
      },
      "source": [
        "- A formatted response with input field looks like as shown below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "F9UQRfjzo4Js",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9UQRfjzo4Js",
        "outputId": "81905d30-8abc-4b4c-95b8-d4966754154a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "तल दियीएको निर्देशन को उचित प्रतिक्रिया दिनुहोस।\n",
            "\n",
            "### प्रतिक्रिया:\n",
            "यसलाई थप संक्षिप्त बनाउन निम्न वाक्य सम्पादन गर्नुहोस्।\n",
            "\n",
            "### इनपुट:\n",
            "पाँच मिनेटमा आइपुग्नु पर्ने बस समात्न उनी दौडिएर बस स्टपमा पुगे ।\n",
            "\n",
            "### प्रतिक्रिया:\n",
            "पाँच मिनेटमा आइपुग्ने भन्दै उनी दौडिएर बस स्टपमा पुगे ।\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### प्रतिक्रिया:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "aFZVopbIlNfx",
      "metadata": {
        "id": "aFZVopbIlNfx"
      },
      "outputs": [],
      "source": [
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "-zf6oht6bIUQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zf6oht6bIUQ",
        "outputId": "47685aaa-950e-470a-e310-b6234ba0c001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set length: 44204\n",
            "Validation set length: 2601\n",
            "Test set length: 5200\n"
          ]
        }
      ],
      "source": [
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcaaf606-f913-4445-8301-632ae10d387d",
      "metadata": {
        "id": "fcaaf606-f913-4445-8301-632ae10d387d"
      },
      "source": [
        "## 7.3 Organizing data into training batches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233f63bd-9755-4d07-8884-5e2e5345cf27",
      "metadata": {
        "id": "233f63bd-9755-4d07-8884-5e2e5345cf27"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-2.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c",
      "metadata": {
        "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c"
      },
      "source": [
        "- We tackle this dataset batching in several steps, as summarized in the figure below\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/detailed-batching.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9af423f-aad9-4b3c-bea5-153021c04862",
      "metadata": {
        "id": "b9af423f-aad9-4b3c-bea5-153021c04862"
      },
      "source": [
        "- First, we implement an `InstructionDataset` class that pre-tokenizes all inputs in the dataset, similar to the `SpamDataset` in chapter 6\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/pretokenizing.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb",
      "metadata": {
        "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### प्रतिक्रिया:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            full_text = data_cleaner.clean_data(full_text)\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "MDz3-wPWnrJF",
      "metadata": {
        "id": "MDz3-wPWnrJF"
      },
      "outputs": [],
      "source": [
        "## load tokenizer\n",
        "import os\n",
        "import requests\n",
        "os.makedirs('NepaliBPE', exist_ok=True)\n",
        "\n",
        "res=requests.get(r\"https://raw.githubusercontent.com/Aananda-giri/GPT2-Nepali/main/2.%20tokenizer/NepaliBPE/tokenizer.json\")\n",
        "with open('NepaliBPE/tokenizer.json','w') as f:\n",
        "    f.write(res.text)\n",
        "\n",
        "res=requests.get(r\"https://raw.githubusercontent.com/Aananda-giri/GPT2-Nepali/main/2.%20tokenizer/NepaliBPE/tokenizer_config.json\")\n",
        "with open('NepaliBPE/tokenizer_config.json','w') as f:\n",
        "    f.write(res.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "fHddZf6lodro",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHddZf6lodro",
        "outputId": "28fe8c72-4c5c-4e0c-dfd7-82b68553b3da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['राम</w>', 'ले</w>', 'भात</w>', 'खायो</w>', '।</w>']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "# Load your tokenizer\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('NepaliBPE')\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\"))\n",
        "tokenizer.tokenize('राम ले भात खायो। ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "vzvqEDbOF995",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzvqEDbOF995",
        "outputId": "178cd083-b0e5-4a50-f7d8-f922a510de02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1685, 285, 12434, 24801, 276]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.encode('राम ले भात खायो।')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "LnrOmoG5Ftk6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnrOmoG5Ftk6",
        "outputId": "cc4cc0f3-d984-4ca1-b1ea-13309a483ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fuck hi\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "tokenizer2 = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer2.encode(\"fuck hi\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "m9ir2gDPuPUK",
      "metadata": {
        "id": "m9ir2gDPuPUK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('data.json','w') as f:\n",
        "  json.dump(data,f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427",
      "metadata": {
        "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427"
      },
      "source": [
        "- In chapter 6, we padded all examples in a dataset to the same length\n",
        "  - Here, we take a more sophisticated approach and develop a custom \"collate\" function that we can pass to the data loader\n",
        "  - This custom collate function pads the training examples in each batch to have the same length (but different batches can have different lengths)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3",
      "metadata": {
        "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/padding.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca",
      "metadata": {
        "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    # and increase the max length by +1, which will add one extra\n",
        "    # padding token below\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to batch_max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        # Via padded[:-1], we remove the extra padded token\n",
        "        # that has been added via the +1 setting in batch_max_length\n",
        "        # (the extra padding token will be relevant in later codes)\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
        "outputId": "2855be73-dbe3-4203-c663-c4dbd5c91b99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_draft_1(batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b",
      "metadata": {
        "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/batching-step-4.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17769a19-b961-4213-92ef-34f441b2d1d6",
      "metadata": {
        "id": "17769a19-b961-4213-92ef-34f441b2d1d6"
      },
      "source": [
        "- Above, we only returned the inputs to the LLM; however, for LLM training, we also need the target values\n",
        "- Similar to pretraining an LLM, the targets are the inputs shifted by 1 position to the right, so the LLM learns to predict the next token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef",
      "metadata": {
        "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/inputs-targets.webp?1\" width=400px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc",
      "metadata": {
        "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
        "outputId": "7e916ed7-daca-4a7c-a240-6e9940032fef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15",
      "metadata": {
        "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15"
      },
      "source": [
        "- Next, we introduce an `ignore_index` value to replace all padding token IDs with a new value; the purpose of this `ignore_index` is that we can ignore padding values in the loss function (more on that later)\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/batching-step-5.webp?1\" width=500px>\n",
        "\n",
        "- Concretely, this means that we replace the token IDs corresponding to `50256` with `-100` as illustrated below"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd4bed33-956e-4b3f-a09c-586d8203109a",
      "metadata": {
        "id": "bd4bed33-956e-4b3f-a09c-586d8203109a"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/ignore-index.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5346513e-c3f4-44fe-af22-4ebd36497728",
      "metadata": {
        "id": "5346513e-c3f4-44fe-af22-4ebd36497728"
      },
      "source": [
        "- (In addition, we also introduce the `allowed_max_length` in case we want to limit the length of the samples; this will be useful if you plan to work with your own datasets that are longer than the 1024 token context size supported by the GPT-2 model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2",
      "metadata": {
        "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
        "outputId": "2835af30-ecfd-43db-f5cc-1f45b138b2ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ],
      "source": [
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7",
      "metadata": {
        "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7"
      },
      "source": [
        "- Let's see what this replacement by -100 accomplishes\n",
        "- For illustration purposes, let's assume we have a small classification task with 2 class labels, 0 and 1, similar to chapter 6\n",
        "- If we have the following logits values (outputs of the last layer of the model), we calculate the following loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524",
      "metadata": {
        "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524"
      },
      "source": [
        "- In practice, it is also common to mask out the target token IDs that correspond to the instruction, as illustrated in the figure below (this is a recommended reader exercise after completing the chapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39",
      "metadata": {
        "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/mask-instructions.webp?1\" width=600px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96",
      "metadata": {
        "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96"
      },
      "source": [
        "## 7.4 Creating data loaders for an instruction dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50",
      "metadata": {
        "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50"
      },
      "source": [
        "- In this section, we use the `InstructionDataset` class and `custom_collate_fn` function to instantiate the training, validation, and test data loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fffe390-b226-4d5c-983f-9f4da773cb82",
      "metadata": {
        "id": "9fffe390-b226-4d5c-983f-9f4da773cb82"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-3.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "932677e9-9317-42e8-b461-7b0269518f97",
      "metadata": {
        "id": "932677e9-9317-42e8-b461-7b0269518f97"
      },
      "source": [
        "- Another additional detail of the previous `custom_collate_fn` function is that we now directly move the data to the target device (e.g., GPU) instead of doing it in the main training loop, which improves efficiency because it can be carried out as a background process when we use the `custom_collate_fn` as part of the data loader\n",
        "- Using the `partial` function from Python's `functools` standard library, we create a new function with the `device` argument of the original function pre-filled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "etpqqWh8phKc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etpqqWh8phKc",
        "outputId": "7ebef4f2-93c7-45b8-c662-22315a2f0a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# However, the resulting loss values may be slightly different.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c",
      "metadata": {
        "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=1024\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a",
      "metadata": {
        "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a"
      },
      "source": [
        "- Next, we instantiate the data loaders similar to previous chapters, except that we now provide our own collate function for the batching process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "BtWkgir6Hlpe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtWkgir6Hlpe",
        "outputId": "b093f7ff-8c9d-4fed-b0a5-13167cb79ec5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-41a104e48929>:22: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"lxml\")\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "1d097dc8-ad34-4f05-b435-e4147965f532",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d097dc8-ad34-4f05-b435-e4147965f532",
        "outputId": "be04b6c3-9cdc-4e24-f4c7-4a0538c9b805"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-41a104e48929>:22: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"lxml\")\n"
          ]
        }
      ],
      "source": [
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pbYYJw7JO90h",
      "metadata": {
        "id": "pbYYJw7JO90h"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "xNYfKjpOO_Dl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNYfKjpOO_Dl",
        "outputId": "e8dbe766-238d-4c31-b4f4-39c7255b117f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "for data in train_loader:\n",
        "  print(print(data[0].shape, data[1].shape))\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "fVdRuzoFBhHJ",
      "metadata": {
        "id": "fVdRuzoFBhHJ"
      },
      "outputs": [],
      "source": [
        "assert inputs.shape[0] == 8, f\"input shape 0 {inputs.shape[0]}\"\n",
        "assert inputs.shape[1] < 300, f\"input shape 1 {inputs.shape[1]}\"\n",
        "assert targets.shape[0] == 8, f\"input shape 0 {inputs.shape[0]}\"\n",
        "assert targets.shape[1] < 300, f\"input shape 1 {inputs.shape[1]}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0",
      "metadata": {
        "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0"
      },
      "source": [
        "- Let's see what the dimensions of the resulting input and target batches look like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "GGs1AI3vHpnX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGs1AI3vHpnX",
        "outputId": "7f0c1835-2453-46f1-a0fa-7c13a8d496fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 295]) torch.Size([8, 295])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 282]) torch.Size([8, 282])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 287]) torch.Size([8, 287])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 258]) torch.Size([8, 258])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 349]) torch.Size([8, 349])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 339]) torch.Size([8, 339])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 287]) torch.Size([8, 287])\n",
            "torch.Size([8, 359]) torch.Size([8, 359])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 270]) torch.Size([8, 270])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 323]) torch.Size([8, 323])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 278]) torch.Size([8, 278])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 369]) torch.Size([8, 369])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 275]) torch.Size([8, 275])\n",
            "torch.Size([8, 346]) torch.Size([8, 346])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 299]) torch.Size([8, 299])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 393]) torch.Size([8, 393])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 300]) torch.Size([8, 300])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 300]) torch.Size([8, 300])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 300]) torch.Size([8, 300])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 552]) torch.Size([8, 552])\n",
            "torch.Size([8, 374]) torch.Size([8, 374])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 296]) torch.Size([8, 296])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 284]) torch.Size([8, 284])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 290]) torch.Size([8, 290])\n",
            "torch.Size([8, 296]) torch.Size([8, 296])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 234]) torch.Size([8, 234])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 294]) torch.Size([8, 294])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 392]) torch.Size([8, 392])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 371]) torch.Size([8, 371])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 278]) torch.Size([8, 278])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 53]) torch.Size([8, 53])\n",
            "torch.Size([8, 268]) torch.Size([8, 268])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 333]) torch.Size([8, 333])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 282]) torch.Size([8, 282])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 279]) torch.Size([8, 279])\n",
            "torch.Size([8, 382]) torch.Size([8, 382])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 292]) torch.Size([8, 292])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 259]) torch.Size([8, 259])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 280]) torch.Size([8, 280])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 251]) torch.Size([8, 251])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 263]) torch.Size([8, 263])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 388]) torch.Size([8, 388])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 317]) torch.Size([8, 317])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 279]) torch.Size([8, 279])\n",
            "torch.Size([8, 291]) torch.Size([8, 291])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 439]) torch.Size([8, 439])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 49]) torch.Size([8, 49])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 335]) torch.Size([8, 335])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 245]) torch.Size([8, 245])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 382]) torch.Size([8, 382])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 253]) torch.Size([8, 253])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 376]) torch.Size([8, 376])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 436]) torch.Size([8, 436])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 283]) torch.Size([8, 283])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 308]) torch.Size([8, 308])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 265]) torch.Size([8, 265])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 311]) torch.Size([8, 311])\n",
            "torch.Size([8, 288]) torch.Size([8, 288])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 299]) torch.Size([8, 299])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 284]) torch.Size([8, 284])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 359]) torch.Size([8, 359])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 290]) torch.Size([8, 290])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 485]) torch.Size([8, 485])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 349]) torch.Size([8, 349])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 248]) torch.Size([8, 248])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 269]) torch.Size([8, 269])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 259]) torch.Size([8, 259])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 311]) torch.Size([8, 311])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 269]) torch.Size([8, 269])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 309]) torch.Size([8, 309])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 288]) torch.Size([8, 288])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 461]) torch.Size([8, 461])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 372]) torch.Size([8, 372])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 259]) torch.Size([8, 259])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 401]) torch.Size([8, 401])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 258]) torch.Size([8, 258])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 796]) torch.Size([8, 796])\n",
            "torch.Size([8, 420]) torch.Size([8, 420])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 340]) torch.Size([8, 340])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 389]) torch.Size([8, 389])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 256]) torch.Size([8, 256])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 54]) torch.Size([8, 54])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 289]) torch.Size([8, 289])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 270]) torch.Size([8, 270])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 558]) torch.Size([8, 558])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 302]) torch.Size([8, 302])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 323]) torch.Size([8, 323])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 285]) torch.Size([8, 285])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 318]) torch.Size([8, 318])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 569]) torch.Size([8, 569])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 416]) torch.Size([8, 416])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 378]) torch.Size([8, 378])\n",
            "torch.Size([8, 234]) torch.Size([8, 234])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 448]) torch.Size([8, 448])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 263]) torch.Size([8, 263])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 283]) torch.Size([8, 283])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 294]) torch.Size([8, 294])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 328]) torch.Size([8, 328])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 396]) torch.Size([8, 396])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 285]) torch.Size([8, 285])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 434]) torch.Size([8, 434])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 278]) torch.Size([8, 278])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 270]) torch.Size([8, 270])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 439]) torch.Size([8, 439])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 297]) torch.Size([8, 297])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 345]) torch.Size([8, 345])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 396]) torch.Size([8, 396])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 334]) torch.Size([8, 334])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 249]) torch.Size([8, 249])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 394]) torch.Size([8, 394])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 326]) torch.Size([8, 326])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 367]) torch.Size([8, 367])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 321]) torch.Size([8, 321])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 305]) torch.Size([8, 305])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 577]) torch.Size([8, 577])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 434]) torch.Size([8, 434])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 284]) torch.Size([8, 284])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 283]) torch.Size([8, 283])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 282]) torch.Size([8, 282])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 289]) torch.Size([8, 289])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 52]) torch.Size([8, 52])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 325]) torch.Size([8, 325])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 248]) torch.Size([8, 248])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 332]) torch.Size([8, 332])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 412]) torch.Size([8, 412])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 245]) torch.Size([8, 245])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 497]) torch.Size([8, 497])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 318]) torch.Size([8, 318])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 627]) torch.Size([8, 627])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 258]) torch.Size([8, 258])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 325]) torch.Size([8, 325])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 248]) torch.Size([8, 248])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 285]) torch.Size([8, 285])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 275]) torch.Size([8, 275])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 351]) torch.Size([8, 351])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 283]) torch.Size([8, 283])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 305]) torch.Size([8, 305])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 253]) torch.Size([8, 253])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 437]) torch.Size([8, 437])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 443]) torch.Size([8, 443])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 268]) torch.Size([8, 268])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 561]) torch.Size([8, 561])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 382]) torch.Size([8, 382])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 323]) torch.Size([8, 323])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 280]) torch.Size([8, 280])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 258]) torch.Size([8, 258])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 253]) torch.Size([8, 253])\n",
            "torch.Size([8, 391]) torch.Size([8, 391])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 306]) torch.Size([8, 306])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 291]) torch.Size([8, 291])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 491]) torch.Size([8, 491])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 360]) torch.Size([8, 360])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 280]) torch.Size([8, 280])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 279]) torch.Size([8, 279])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 238]) torch.Size([8, 238])\n",
            "torch.Size([8, 279]) torch.Size([8, 279])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 52]) torch.Size([8, 52])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 297]) torch.Size([8, 297])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 258]) torch.Size([8, 258])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 629]) torch.Size([8, 629])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 316]) torch.Size([8, 316])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 269]) torch.Size([8, 269])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 251]) torch.Size([8, 251])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 287]) torch.Size([8, 287])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 51]) torch.Size([8, 51])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 409]) torch.Size([8, 409])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 283]) torch.Size([8, 283])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 280]) torch.Size([8, 280])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 380]) torch.Size([8, 380])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 268]) torch.Size([8, 268])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 253]) torch.Size([8, 253])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 310]) torch.Size([8, 310])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 301]) torch.Size([8, 301])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 295]) torch.Size([8, 295])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 310]) torch.Size([8, 310])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 350]) torch.Size([8, 350])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 332]) torch.Size([8, 332])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 284]) torch.Size([8, 284])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 333]) torch.Size([8, 333])\n",
            "torch.Size([8, 275]) torch.Size([8, 275])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 365]) torch.Size([8, 365])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 269]) torch.Size([8, 269])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 399]) torch.Size([8, 399])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 330]) torch.Size([8, 330])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 258]) torch.Size([8, 258])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 381]) torch.Size([8, 381])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 302]) torch.Size([8, 302])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 328]) torch.Size([8, 328])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 296]) torch.Size([8, 296])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 265]) torch.Size([8, 265])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 357]) torch.Size([8, 357])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 387]) torch.Size([8, 387])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 273]) torch.Size([8, 273])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 307]) torch.Size([8, 307])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 402]) torch.Size([8, 402])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 263]) torch.Size([8, 263])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 355]) torch.Size([8, 355])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 336]) torch.Size([8, 336])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 373]) torch.Size([8, 373])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 273]) torch.Size([8, 273])\n",
            "torch.Size([8, 270]) torch.Size([8, 270])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 311]) torch.Size([8, 311])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 317]) torch.Size([8, 317])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 296]) torch.Size([8, 296])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 253]) torch.Size([8, 253])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 245]) torch.Size([8, 245])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 375]) torch.Size([8, 375])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 278]) torch.Size([8, 278])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 290]) torch.Size([8, 290])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 237]) torch.Size([8, 237])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 310]) torch.Size([8, 310])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 291]) torch.Size([8, 291])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 270]) torch.Size([8, 270])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 401]) torch.Size([8, 401])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 304]) torch.Size([8, 304])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 43]) torch.Size([8, 43])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 339]) torch.Size([8, 339])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 284]) torch.Size([8, 284])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 363]) torch.Size([8, 363])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 251]) torch.Size([8, 251])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 288]) torch.Size([8, 288])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 302]) torch.Size([8, 302])\n",
            "torch.Size([8, 353]) torch.Size([8, 353])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 342]) torch.Size([8, 342])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 362]) torch.Size([8, 362])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 356]) torch.Size([8, 356])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 328]) torch.Size([8, 328])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 285]) torch.Size([8, 285])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 245]) torch.Size([8, 245])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 319]) torch.Size([8, 319])\n",
            "torch.Size([8, 263]) torch.Size([8, 263])\n",
            "torch.Size([8, 302]) torch.Size([8, 302])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 315]) torch.Size([8, 315])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 369]) torch.Size([8, 369])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 305]) torch.Size([8, 305])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 301]) torch.Size([8, 301])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 357]) torch.Size([8, 357])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 332]) torch.Size([8, 332])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 317]) torch.Size([8, 317])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 296]) torch.Size([8, 296])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 291]) torch.Size([8, 291])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 249]) torch.Size([8, 249])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 317]) torch.Size([8, 317])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 436]) torch.Size([8, 436])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 267]) torch.Size([8, 267])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 352]) torch.Size([8, 352])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 240]) torch.Size([8, 240])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 224]) torch.Size([8, 224])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 327]) torch.Size([8, 327])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 418]) torch.Size([8, 418])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 277]) torch.Size([8, 277])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 248]) torch.Size([8, 248])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 236]) torch.Size([8, 236])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 234]) torch.Size([8, 234])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 338]) torch.Size([8, 338])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 258]) torch.Size([8, 258])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 288]) torch.Size([8, 288])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 243]) torch.Size([8, 243])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 272]) torch.Size([8, 272])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 282]) torch.Size([8, 282])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 287]) torch.Size([8, 287])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 273]) torch.Size([8, 273])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 395]) torch.Size([8, 395])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 378]) torch.Size([8, 378])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 255]) torch.Size([8, 255])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 223]) torch.Size([8, 223])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 288]) torch.Size([8, 288])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 208]) torch.Size([8, 208])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 539]) torch.Size([8, 539])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 244]) torch.Size([8, 244])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 213]) torch.Size([8, 213])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 279]) torch.Size([8, 279])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 269]) torch.Size([8, 269])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 280]) torch.Size([8, 280])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 295]) torch.Size([8, 295])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 228]) torch.Size([8, 228])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 251]) torch.Size([8, 251])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 212]) torch.Size([8, 212])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 286]) torch.Size([8, 286])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 292]) torch.Size([8, 292])\n",
            "torch.Size([8, 297]) torch.Size([8, 297])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 202]) torch.Size([8, 202])\n",
            "torch.Size([8, 268]) torch.Size([8, 268])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 275]) torch.Size([8, 275])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 234]) torch.Size([8, 234])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 393]) torch.Size([8, 393])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 251]) torch.Size([8, 251])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 398]) torch.Size([8, 398])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 357]) torch.Size([8, 357])\n",
            "torch.Size([8, 226]) torch.Size([8, 226])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 257]) torch.Size([8, 257])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 96]) torch.Size([8, 96])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 198]) torch.Size([8, 198])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 105]) torch.Size([8, 105])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 176]) torch.Size([8, 176])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 274]) torch.Size([8, 274])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 631]) torch.Size([8, 631])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 229]) torch.Size([8, 229])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 293]) torch.Size([8, 293])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 308]) torch.Size([8, 308])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 201]) torch.Size([8, 201])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 247]) torch.Size([8, 247])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 217]) torch.Size([8, 217])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 189]) torch.Size([8, 189])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 285]) torch.Size([8, 285])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 390]) torch.Size([8, 390])\n",
            "torch.Size([8, 391]) torch.Size([8, 391])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 266]) torch.Size([8, 266])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 294]) torch.Size([8, 294])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 311]) torch.Size([8, 311])\n",
            "torch.Size([8, 246]) torch.Size([8, 246])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 84]) torch.Size([8, 84])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 288]) torch.Size([8, 288])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 250]) torch.Size([8, 250])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 111]) torch.Size([8, 111])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 200]) torch.Size([8, 200])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 259]) torch.Size([8, 259])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 233]) torch.Size([8, 233])\n",
            "torch.Size([8, 181]) torch.Size([8, 181])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 317]) torch.Size([8, 317])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 422]) torch.Size([8, 422])\n",
            "torch.Size([8, 290]) torch.Size([8, 290])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 192]) torch.Size([8, 192])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 242]) torch.Size([8, 242])\n",
            "torch.Size([8, 159]) torch.Size([8, 159])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 225]) torch.Size([8, 225])\n",
            "torch.Size([8, 322]) torch.Size([8, 322])\n",
            "torch.Size([8, 303]) torch.Size([8, 303])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 141]) torch.Size([8, 141])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 305]) torch.Size([8, 305])\n",
            "torch.Size([8, 103]) torch.Size([8, 103])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 230]) torch.Size([8, 230])\n",
            "torch.Size([8, 178]) torch.Size([8, 178])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 293]) torch.Size([8, 293])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 55]) torch.Size([8, 55])\n",
            "torch.Size([8, 214]) torch.Size([8, 214])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 120]) torch.Size([8, 120])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 239]) torch.Size([8, 239])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 167]) torch.Size([8, 167])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 428]) torch.Size([8, 428])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 234]) torch.Size([8, 234])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 171]) torch.Size([8, 171])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 227]) torch.Size([8, 227])\n",
            "torch.Size([8, 260]) torch.Size([8, 260])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 360]) torch.Size([8, 360])\n",
            "torch.Size([8, 95]) torch.Size([8, 95])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 261]) torch.Size([8, 261])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 196]) torch.Size([8, 196])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 334]) torch.Size([8, 334])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 184]) torch.Size([8, 184])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 249]) torch.Size([8, 249])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 241]) torch.Size([8, 241])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 291]) torch.Size([8, 291])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 46]) torch.Size([8, 46])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 216]) torch.Size([8, 216])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 132]) torch.Size([8, 132])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 197]) torch.Size([8, 197])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 307]) torch.Size([8, 307])\n",
            "torch.Size([8, 194]) torch.Size([8, 194])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 209]) torch.Size([8, 209])\n",
            "torch.Size([8, 429]) torch.Size([8, 429])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 249]) torch.Size([8, 249])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 460]) torch.Size([8, 460])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 299]) torch.Size([8, 299])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 215]) torch.Size([8, 215])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 245]) torch.Size([8, 245])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 131]) torch.Size([8, 131])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 221]) torch.Size([8, 221])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 124]) torch.Size([8, 124])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 203]) torch.Size([8, 203])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 393]) torch.Size([8, 393])\n",
            "torch.Size([8, 157]) torch.Size([8, 157])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 380]) torch.Size([8, 380])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 151]) torch.Size([8, 151])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 94]) torch.Size([8, 94])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 113]) torch.Size([8, 113])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 172]) torch.Size([8, 172])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 101]) torch.Size([8, 101])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 187]) torch.Size([8, 187])\n",
            "torch.Size([8, 139]) torch.Size([8, 139])\n",
            "torch.Size([8, 183]) torch.Size([8, 183])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 188]) torch.Size([8, 188])\n",
            "torch.Size([8, 232]) torch.Size([8, 232])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 220]) torch.Size([8, 220])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 193]) torch.Size([8, 193])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 162]) torch.Size([8, 162])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 145]) torch.Size([8, 145])\n",
            "torch.Size([8, 106]) torch.Size([8, 106])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 401]) torch.Size([8, 401])\n",
            "torch.Size([8, 204]) torch.Size([8, 204])\n",
            "torch.Size([8, 179]) torch.Size([8, 179])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 90]) torch.Size([8, 90])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 99]) torch.Size([8, 99])\n",
            "torch.Size([8, 121]) torch.Size([8, 121])\n",
            "torch.Size([8, 289]) torch.Size([8, 289])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 191]) torch.Size([8, 191])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 128]) torch.Size([8, 128])\n",
            "torch.Size([8, 146]) torch.Size([8, 146])\n",
            "torch.Size([8, 271]) torch.Size([8, 271])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 108]) torch.Size([8, 108])\n",
            "torch.Size([8, 147]) torch.Size([8, 147])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 173]) torch.Size([8, 173])\n",
            "torch.Size([8, 100]) torch.Size([8, 100])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 107]) torch.Size([8, 107])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 406]) torch.Size([8, 406])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 252]) torch.Size([8, 252])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 231]) torch.Size([8, 231])\n",
            "torch.Size([8, 110]) torch.Size([8, 110])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 102]) torch.Size([8, 102])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 158]) torch.Size([8, 158])\n",
            "torch.Size([8, 254]) torch.Size([8, 254])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 174]) torch.Size([8, 174])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 134]) torch.Size([8, 134])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 142]) torch.Size([8, 142])\n",
            "torch.Size([8, 235]) torch.Size([8, 235])\n",
            "torch.Size([8, 177]) torch.Size([8, 177])\n",
            "torch.Size([8, 264]) torch.Size([8, 264])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 219]) torch.Size([8, 219])\n",
            "torch.Size([8, 210]) torch.Size([8, 210])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 135]) torch.Size([8, 135])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 143]) torch.Size([8, 143])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 444]) torch.Size([8, 444])\n",
            "torch.Size([8, 222]) torch.Size([8, 222])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 130]) torch.Size([8, 130])\n",
            "torch.Size([8, 569]) torch.Size([8, 569])\n",
            "torch.Size([8, 182]) torch.Size([8, 182])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 190]) torch.Size([8, 190])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 199]) torch.Size([8, 199])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 125]) torch.Size([8, 125])\n",
            "torch.Size([8, 165]) torch.Size([8, 165])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n",
            "torch.Size([8, 186]) torch.Size([8, 186])\n",
            "torch.Size([8, 138]) torch.Size([8, 138])\n",
            "torch.Size([8, 122]) torch.Size([8, 122])\n",
            "torch.Size([8, 262]) torch.Size([8, 262])\n",
            "torch.Size([8, 180]) torch.Size([8, 180])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 118]) torch.Size([8, 118])\n",
            "torch.Size([8, 299]) torch.Size([8, 299])\n",
            "torch.Size([8, 195]) torch.Size([8, 195])\n",
            "torch.Size([8, 281]) torch.Size([8, 281])\n",
            "torch.Size([8, 92]) torch.Size([8, 92])\n",
            "torch.Size([8, 133]) torch.Size([8, 133])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 155]) torch.Size([8, 155])\n",
            "torch.Size([8, 126]) torch.Size([8, 126])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 97]) torch.Size([8, 97])\n",
            "torch.Size([8, 115]) torch.Size([8, 115])\n",
            "torch.Size([8, 334]) torch.Size([8, 334])\n",
            "torch.Size([8, 218]) torch.Size([8, 218])\n",
            "torch.Size([8, 160]) torch.Size([8, 160])\n",
            "torch.Size([8, 249]) torch.Size([8, 249])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 152]) torch.Size([8, 152])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 116]) torch.Size([8, 116])\n",
            "torch.Size([8, 170]) torch.Size([8, 170])\n",
            "torch.Size([8, 117]) torch.Size([8, 117])\n",
            "torch.Size([8, 153]) torch.Size([8, 153])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 98]) torch.Size([8, 98])\n",
            "torch.Size([8, 163]) torch.Size([8, 163])\n",
            "torch.Size([8, 205]) torch.Size([8, 205])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 93]) torch.Size([8, 93])\n",
            "torch.Size([8, 168]) torch.Size([8, 168])\n",
            "torch.Size([8, 129]) torch.Size([8, 129])\n",
            "torch.Size([8, 127]) torch.Size([8, 127])\n",
            "torch.Size([8, 166]) torch.Size([8, 166])\n",
            "torch.Size([8, 137]) torch.Size([8, 137])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 169]) torch.Size([8, 169])\n",
            "torch.Size([8, 154]) torch.Size([8, 154])\n",
            "torch.Size([8, 185]) torch.Size([8, 185])\n",
            "torch.Size([8, 149]) torch.Size([8, 149])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 140]) torch.Size([8, 140])\n",
            "torch.Size([8, 123]) torch.Size([8, 123])\n",
            "torch.Size([8, 207]) torch.Size([8, 207])\n",
            "torch.Size([8, 136]) torch.Size([8, 136])\n",
            "torch.Size([8, 175]) torch.Size([8, 175])\n",
            "torch.Size([8, 144]) torch.Size([8, 144])\n",
            "torch.Size([8, 112]) torch.Size([8, 112])\n",
            "torch.Size([8, 211]) torch.Size([8, 211])\n",
            "torch.Size([8, 109]) torch.Size([8, 109])\n",
            "torch.Size([8, 164]) torch.Size([8, 164])\n",
            "torch.Size([8, 156]) torch.Size([8, 156])\n",
            "torch.Size([8, 114]) torch.Size([8, 114])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 148]) torch.Size([8, 148])\n",
            "torch.Size([8, 104]) torch.Size([8, 104])\n",
            "torch.Size([8, 119]) torch.Size([8, 119])\n",
            "torch.Size([8, 161]) torch.Size([8, 161])\n",
            "torch.Size([8, 206]) torch.Size([8, 206])\n",
            "torch.Size([8, 150]) torch.Size([8, 150])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "count=0\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)\n",
        "    assert inputs.shape[0] == 8, f\"input shape 0 {inputs.shape[0]}\"\n",
        "    # assert inputs.shape[1] < 1000, f\"input shape 1 {inputs.shape[1]}\"\n",
        "    assert targets.shape[0] == 8, f\"input shape 0 {inputs.shape[0]}\"\n",
        "    # assert targets.shape[1] < 1000, f\"input shape 1 {inputs.shape[1]}\"\n",
        "    # count +=1\n",
        "    # if count>10:break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657",
      "metadata": {
        "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657"
      },
      "source": [
        "- As we can see based on the output above, all batches have a batch size of 8 but a different length, as expected\n",
        "- Let's also double-check that the inputs contain the `<|endoftext|>` padding tokens corresponding to token ID 50256 by printing the contents of the first training example in the `inputs` batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
        "outputId": "2abe9299-bbaa-4122-8a55-d52bd9224259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 4051,   325,  8808,   298,  1771,   280,  3980,  4159,  4292,  8695,\n",
            "          276,  4159,  3231,  1657,   999,   594,   303,  2922,  1716,  1328,\n",
            "          448, 16610,   276,  8439,  1716, 15647, 35985,  9209,   276,  4159,\n",
            "        38982, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n"
          ]
        }
      ],
      "source": [
        "print(inputs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360",
      "metadata": {
        "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360"
      },
      "source": [
        "- Similarly, we visually double-check that the targets contain the -100 placeholder tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
        "outputId": "f4f3f124-7e9d-4459-9363-766e3aa71934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([  325,  8808,   298,  1771,   280,  3980,  4159,  4292,  8695,   276,\n",
            "         4159,  3231,  1657,   999,   594,   303,  2922,  1716,  1328,   448,\n",
            "        16610,   276,  8439,  1716, 15647, 35985,  9209,   276,  4159, 38982,\n",
            "        50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"
          ]
        }
      ],
      "source": [
        "print(targets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6aad445-8f19-4238-b9bf-db80767fb91a",
      "metadata": {
        "id": "d6aad445-8f19-4238-b9bf-db80767fb91a"
      },
      "source": [
        "## 7.5 Loading a pretrained LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a5c07d1-4fc9-4846-94cf-b11a085a667b",
      "metadata": {
        "id": "5a5c07d1-4fc9-4846-94cf-b11a085a667b"
      },
      "source": [
        "- In this section, we load a pretrained GPT model using the same code that we used in section 5.5 of chapter 5 and section 6.4 in chapter 6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d1b438f-88af-413f-96a9-f059c6c55fc4",
      "metadata": {
        "id": "8d1b438f-88af-413f-96a9-f059c6c55fc4"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-4.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c68eda7-e02e-4caa-846b-ca6dbd396ca2",
      "metadata": {
        "id": "8c68eda7-e02e-4caa-846b-ca6dbd396ca2"
      },
      "source": [
        "- However, instead of loading the smallest 124 million parameter model, we load the medium version with 355 million parameters since the 124 million model is too small for achieving qualitatively reasonable results via instruction finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "821H2j8-wA-W",
      "metadata": {
        "id": "821H2j8-wA-W"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "res = requests.get('https://raw.githubusercontent.com/Aananda-giri/GPT2-Nepali/main/3.%20GPT2-Nepali/2_inference/gpt_model.py')\n",
        "with open('gpt_model.py','w') as f:\n",
        "    f.write(res.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "uP8QGusPw_hF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP8QGusPw_hF",
        "outputId": "fa2a2cb1-7d78-4dd3-c23b-f5ac255d646e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "रामले भात खाने गरेका थिए ।\n"
          ]
        }
      ],
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from gpt_model import GPTModel, GPT_CONFIG_124M, generate\n",
        "\n",
        "\n",
        "# load the model\n",
        "# ----------------------------\n",
        "\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# checkpoint = torch.load('/kaggle/input/sebastian-v4/model_checkpoints/model_pg_190000_steps.pth', weights_only=False)\n",
        "# # modified (added model loading code)\n",
        "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "model = GPTModel.from_pretrained(\"Aananda-giri/GPT2-Nepali\")\n",
        "model.to(device)\n",
        "\n",
        "# load the tokenizer\n",
        "# ----------------------------\n",
        "# tokenizer = PreTrainedTokenizerFast.from_pretrained(\"Aananda-giri/NepaliBPE\")\n",
        "\n",
        "\n",
        "# generate a sample\n",
        "# ----------------------------\n",
        "\n",
        "prompt = \"रामले भात\"\n",
        "\n",
        "generated_text = generate(\n",
        "    model,\n",
        "    prompt,\n",
        "    tokenizer,\n",
        "    max_new_tokens=100,\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    top_p=None,  # New parameter for nucleus sampling\n",
        "    eos_id=None,\n",
        "    repetition_penalty=1.2,\n",
        "    penalize_len_below=50\n",
        ")\n",
        "\n",
        "model.eval();\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf3afed-bc8e-4d3a-ad9d-eb6f57bb7af5",
      "metadata": {
        "id": "dbf3afed-bc8e-4d3a-ad9d-eb6f57bb7af5"
      },
      "source": [
        "- Before we start finetuning the model in the next section, let's see how it performs on one of the validation tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "kPzOnCA-1now",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPzOnCA-1now",
        "outputId": "5225a8de-fa81-4e57-987d-97a6009c4fd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': 'सङ्क्रमणकालीन शब्दहरूले लेखनमा कसरी मद्दत गर्छ भनी व्याख्या गर्नुहोस्',\n",
              " 'input': '\"<noinput>\"',\n",
              " 'output': 'संक्रमणकालीन शब्दहरू र वाक्यांशहरूको प्रयोगले वाक्य, अनुच्छेद, र विचारहरूलाई लिखित रूपमा एकसाथ जोड्न मद्दत गर्दछ। तिनीहरूले एक विचारलाई जोड दिन सक्छन्, संक्रमणको संकेत गर्न सक्छन्, वा दुई विचारहरू बीचको सम्बन्ध सिर्जना गर्न सक्छन्। ट्रान्जिसनले लिखित रूपमा तथ्य, विचार र विचारहरू बीचको सम्बन्ध देखाउने अवसर प्रदान गर्दछ। पाठकहरूलाई लिखित सामग्रीलाई अझ राम्ररी बुझ्न र व्याख्या गर्न मद्दत गर्दै पाठ सुसंगत रूपमा प्रवाहित हुन्छ भनी सुनिश्चित गर्न तिनीहरूले मद्दत गर्न सक्छन्। ट्रान्जिसनहरूले लेखनमा महत्त्वपूर्ण संरचनात्मक भूमिका प्रदान गर्दछ, पाठकहरूलाई सजिलैसँग लेखकका विचारहरू पछ्याउन मद्दत गर्दछ।',\n",
              " 'id': 49404}"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "7bd32b7c-5b44-4d25-a09f-46836802ca74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bd32b7c-5b44-4d25-a09f-46836802ca74",
        "outputId": "5d6101d6-1cbe-4c30-cd76-e9ca765ba1ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "तल दियीएको निर्देशन को उचित प्रतिक्रिया दिनुहोस।\n",
            "\n",
            "### प्रतिक्रिया:\n",
            "सङ्क्रमणकालीन शब्दहरूले लेखनमा कसरी मद्दत गर्छ भनी व्याख्या गर्नुहोस्\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "R9shGC3O0drk",
      "metadata": {
        "id": "R9shGC3O0drk"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "res = requests.get(\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/previous_chapters.py\")\n",
        "with open('previous_chapters.py','w') as f:\n",
        "  f.write(res.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "2e3e68e0-2627-4c65-b4e7-1e0667e4f6fa",
      "metadata": {
        "id": "2e3e68e0-2627-4c65-b4e7-1e0667e4f6fa"
      },
      "outputs": [],
      "source": [
        "from gpt_model import (\n",
        "    generate,\n",
        "    # text_to_token_ids,\n",
        "    # token_ids_to_text\n",
        ")\n",
        "\n",
        "\n",
        "# token_ids = generate(\n",
        "#     model=model,\n",
        "#     idx=text_to_token_ids(input_text, tokenizer),\n",
        "#     max_new_tokens=35,\n",
        "#     context_size=BASE_CONFIG[\"context_length\"],\n",
        "#     eos_id=50256,\n",
        "# )\n",
        "#  = token_ids_to_text(token_ids, tokenizer)\n",
        "\n",
        "generated_text = generate(\n",
        "    model,\n",
        "    input_text,\n",
        "    tokenizer,\n",
        "    max_new_tokens=35,\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    top_p=None,  # New parameter for nucleus sampling\n",
        "    eos_id=None,\n",
        "    repetition_penalty=1.2,\n",
        "    penalize_len_below=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "NurJx0_u1b4z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "NurJx0_u1b4z",
        "outputId": "6c10d885-ee66-4f82-bc5d-8a2885f0256f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'तल दियीएको निर्देशन को उचित प्रतिक्रिया दिनुहोस।\\n\\n### प्रतिक्रिया:\\nसङ्क्रमणकालीन शब्दहरूले लेखनमा कसरी मद्दत गर्छ भनी व्याख्या गर्नुहोस्'"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36e2fda5-f796-4954-8f72-1dd1123e3344",
      "metadata": {
        "id": "36e2fda5-f796-4954-8f72-1dd1123e3344"
      },
      "source": [
        "- Note that the `generate` function we used in previous chapters returns the combined input and output text, which was convenient in the previous section for creating legible text\n",
        "- To isolate the response, we can subtract the length of the instruction from the start of the `generated_text`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "ba4a55bf-a245-48d8-beda-2838a58fb5ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba4a55bf-a245-48d8-beda-2838a58fb5ba",
        "outputId": "2f7859eb-88ce-44ef-fa76-5dd4a68d78f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ोस् । हामी त्यही अनुरुप नै अघि बढिहाल्छौं उनले भने जस्तो '\n"
          ]
        }
      ],
      "source": [
        "response_text = (\n",
        "    generated_text[len(input_text):]\n",
        "    .replace(\"### प्रतिक्रिया:\", \"\")\n",
        "    .strip()\n",
        ")\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d44080b2-a4c5-4520-a797-549519f66a3e",
      "metadata": {
        "id": "d44080b2-a4c5-4520-a797-549519f66a3e"
      },
      "source": [
        "- As we can see, the model is not capable of following the instructions, yet; it creates a \"Response\" section but it simply repeats the original input sentence as well as the instruction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d27b9d-a942-4cf5-b797-848c5f01e723",
      "metadata": {
        "id": "70d27b9d-a942-4cf5-b797-848c5f01e723"
      },
      "source": [
        "## 7.6 Finetuning the LLM on instruction data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "314b2a39-88b4-44d8-8c85-1c5b0cd6cc4a",
      "metadata": {
        "id": "314b2a39-88b4-44d8-8c85-1c5b0cd6cc4a"
      },
      "source": [
        "- In this section, we finetune the model\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-5.webp?1\" width=500px>\n",
        "\n",
        "- Note that we can reuse all the loss calculation and training functions that we used in previous chapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "65444865-df87-4d98-9faf-875e1c4be860",
      "metadata": {
        "id": "65444865-df87-4d98-9faf-875e1c4be860"
      },
      "outputs": [],
      "source": [
        "from previous_chapters import (\n",
        "    calc_loss_loader,\n",
        "    train_model_simple\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00083059-aa41-4d37-8a17-1c72d1b1ca00",
      "metadata": {
        "id": "00083059-aa41-4d37-8a17-1c72d1b1ca00"
      },
      "source": [
        "- Let's calculate the initial training and validation set loss before we start training (as in previous chapters, the goal is to minimize the loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "d99fc6f8-63b2-43da-adbb-a7b6b92c8dd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "d99fc6f8-63b2-43da-adbb-a7b6b92c8dd5",
        "outputId": "88de43c8-d7d6-4072-bfc5-609948dcbc63"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-71f5663297d2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/previous_chapters.py\u001b[0m in \u001b[0;36mcalc_loss_loader\u001b[0;34m(data_loader, model, device, num_batches)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/previous_chapters.py\u001b[0m in \u001b[0;36mcalc_loss_batch\u001b[0;34m(input_batch, target_batch, model, device)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_loss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gpt_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, in_idx)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtok_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mpos_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_embeds\u001b[0m  \u001b[0;31m# Shape [batch_size, num_tokens, emb_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12a6da8f-15b3-42b0-a136-619b7a35c3e9",
      "metadata": {
        "id": "12a6da8f-15b3-42b0-a136-619b7a35c3e9"
      },
      "source": [
        "- Note that the training is a bit more expensive than in previous chapters since we are using a larger model (355 million instead of 124 million parameters)\n",
        "- The runtimes for various devices are shown for reference below (running this notebook on a compatible GPU device requires no changes to the code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db4b57fb-e689-4550-931c-6d34a932487c",
      "metadata": {
        "id": "db4b57fb-e689-4550-931c-6d34a932487c"
      },
      "source": [
        "<div style=\"text-align: left;\">\n",
        "    \n",
        "| Model              | Device                | Runtime for 2 Epochs |\n",
        "|--------------------|-----------------------|----------------------|\n",
        "| gpt2-medium (355M) | CPU (M3 MacBook Air)  | 15.78 minutes        |\n",
        "| gpt2-medium (355M) | GPU (M3 MacBook Air)  | 10.77 minutes        |\n",
        "| gpt2-medium (355M) | GPU (L4)              | 1.83 minutes         |\n",
        "| gpt2-medium (355M) | GPU (A100)            | 0.86 minutes         |\n",
        "| gpt2-small (124M)  | CPU (M3 MacBook Air)  | 5.74 minutes         |\n",
        "| gpt2-small (124M)  | GPU (M3 MacBook Air)  | 3.73 minutes         |\n",
        "| gpt2-small (124M)  | GPU (L4)              | 0.69 minutes         |\n",
        "| gpt2-small (124M)  | GPU (A100)            | 0.39 minutes         |\n",
        "\n",
        "</div>\n",
        "\n",
        "- I ran this notebook using the `\"gpt2-medium (355M)\"` model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78bcf83a-1fff-4540-97c1-765c4016d5e3",
      "metadata": {
        "id": "78bcf83a-1fff-4540-97c1-765c4016d5e3"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ise3wGjlB-iq",
      "metadata": {
        "id": "Ise3wGjlB-iq"
      },
      "source": [
        "- As we can see based on the outputs above, the model trains well, as we can tell based on the decreasing training loss and validation loss values\n",
        "- Furthermore, based on the response text printed after each epoch, we can see that the model correctly follows the instruction to convert the input sentence `'The chef cooks the meal every day.'` into passive voice `'The meal is cooked every day by the chef.'` (We will properly format and evaluate the responses in a later section)\n",
        "- Finally, let's take a look at the training and validation loss curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4acd368b-1403-4807-a218-9102e35bfdbb",
      "metadata": {
        "id": "4acd368b-1403-4807-a218-9102e35bfdbb"
      },
      "outputs": [],
      "source": [
        "from previous_chapters import plot_losses\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6777e0c4-d82c-46d8-84fb-1376c4f8bae0",
      "metadata": {
        "id": "6777e0c4-d82c-46d8-84fb-1376c4f8bae0"
      },
      "source": [
        "- As we can see, the loss decreases sharply at the beginning of the first epoch, which means the model starts learning quickly\n",
        "- We can see that slight overfitting sets in at around 1 training epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3",
      "metadata": {
        "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3"
      },
      "source": [
        "## 7.7 Extracting and saving responses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49",
      "metadata": {
        "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-6.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427",
      "metadata": {
        "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427"
      },
      "source": [
        "- In this section, we save the test set responses for scoring in the next section\n",
        "- We also save a copy of the model for future use\n",
        "- But first, let's take a brief look at the responses generated by the finetuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VQ2NZMbfucAc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ2NZMbfucAc",
        "outputId": "8416b4ac-1993-4628-dea6-7789cdc8926c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ab64c1-586f-4939-8def-23feeb1b3599",
      "metadata": {
        "id": "49ab64c1-586f-4939-8def-23feeb1b3599"
      },
      "source": [
        "- As we can see based on the test set instructions, given responses, and the model's responses, the model performs relatively well\n",
        "- The answers to the first and last instructions are clearly correct\n",
        "- The second answer is close; the model answers with \"cumulus cloud\" instead of \"cumulonimbus\" (however, note that cumulus clouds can develop into cumulonimbus clouds, which are capable of producing thunderstorms)\n",
        "- Most importantly, we can see that model evaluation is not as straightforward as in the previous chapter, where we just had to calculate the percentage of correct spam/non-spam class labels to obtain the classification accuracy\n",
        "- In practice, instruction-finetuned LLMs such as chatbots are evaluated via multiple approaches\n",
        "  - short-answer and multiple choice benchmarks such as MMLU (\"Measuring Massive Multitask Language Understanding\", [https://arxiv.org/abs/2009.03300](https://arxiv.org/abs/2009.03300)), which test the knowledge of a model\n",
        "  - human preference comparison to other LLMs, such as LMSYS chatbot arena ([https://arena.lmsys.org](https://arena.lmsys.org))\n",
        "  - automated conversational benchmarks, where another LLM like GPT-4 is used to evaluate the responses, such as AlpacaEval ([https://tatsu-lab.github.io/alpaca_eval/](https://tatsu-lab.github.io/alpaca_eval/))\n",
        "\n",
        "- In the next section, we will use an approach similar to AlpacaEval and use another LLM to evaluate the responses of our model; however, we will use our own test set instead of using a publicly available benchmark dataset\n",
        "- For this, we add the model response to the `test_data` dictionary and save it as a `\"instruction-data-with-response.json\"` file for record-keeping so that we can load and analyze it in separate Python sessions if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-PNGKzY4snKP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PNGKzY4snKP",
        "outputId": "0453dfb3-51cd-49e2-9e63-f65b606c3478"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 110/110 [01:11<00:00,  1.54it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228d6fa7-d162-44c3-bef1-4013c027b155",
      "metadata": {
        "id": "228d6fa7-d162-44c3-bef1-4013c027b155"
      },
      "source": [
        "- Let's double-check one of the entries to see whether the responses have been added to the `test_data` dictionary correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u-AvCCMTnPSE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-AvCCMTnPSE",
        "outputId": "ce3b2545-8990-4446-e44c-a945e0049c06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
          ]
        }
      ],
      "source": [
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b2f3f6-8569-405a-9db6-d47cba65608a",
      "metadata": {
        "id": "c1b2f3f6-8569-405a-9db6-d47cba65608a"
      },
      "source": [
        "- Finally, we also save the model in case we want to reuse it in the future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cBU0iHmVfOI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cBU0iHmVfOI",
        "outputId": "d6e7f226-9310-43f5-f31f-adc3a893a8e9",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")\n",
        "\n",
        "# Load model via\n",
        "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "obgoGI89dgPm",
      "metadata": {
        "id": "obgoGI89dgPm"
      },
      "source": [
        "## 7.8 Evaluating the finetuned LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "805b9d30-7336-499f-abb5-4a21be3129f5",
      "metadata": {
        "id": "805b9d30-7336-499f-abb5-4a21be3129f5"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-7.webp?1\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68d2b9d3-b6ff-4533-a89d-7b66079b4fd1",
      "metadata": {
        "id": "68d2b9d3-b6ff-4533-a89d-7b66079b4fd1"
      },
      "source": [
        "- In this section, we automate the response evaluation of the finetuned LLM using another, larger LLM\n",
        "- In particular, we use an instruction-finetuned 8-billion-parameter Llama 3 model by Meta AI that can be run locally via ollama ([https://ollama.com](https://ollama.com))\n",
        "- (Alternatively, if you prefer using a more capable LLM like GPT-4 via the OpenAI API, please see the [llm-instruction-eval-openai.ipynb](../03_model-evaluation/llm-instruction-eval-openai.ipynb) notebook)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea427a30-36ba-44e3-bb1f-eb0d7008d6e9",
      "metadata": {
        "id": "ea427a30-36ba-44e3-bb1f-eb0d7008d6e9"
      },
      "source": [
        "- Ollama is an application to run LLMs efficiently\n",
        "- It is a wrapper around llama.cpp ([https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)), which implements LLMs in pure C/C++ to maximize efficiency\n",
        "- Note that it is a tool for using LLMs to generate text (inference), not training or finetuning LLMs\n",
        "- Before running the code below, install ollama by visiting [https://ollama.com](https://ollama.com) and following the instructions (for instance, clicking on the \"Download\" button and downloading the ollama application for your operating system)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747a2fc7-282d-47ec-a987-ed0a23ed6822",
      "metadata": {
        "id": "747a2fc7-282d-47ec-a987-ed0a23ed6822"
      },
      "source": [
        "- For macOS and Windows users, click on the ollama application you downloaded; if it prompts you to install the command line usage, say \"yes\"\n",
        "- Linux users can use the installation command provided on the ollama website\n",
        "\n",
        "- In general, before we can use ollama from the command line, we have to either start the ollama application or run `ollama serve` in a separate terminal\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/ollama-run.webp?1\" width=700px>\n",
        "\n",
        "\n",
        "- With the ollama application or `ollama serve` running in a different terminal, on the command line, execute the following command to try out the 8-billion-parameter Llama 3 model (the model, which takes up 4.7 GB of storage space, will be automatically downloaded the first time you execute this command)\n",
        "\n",
        "```bash\n",
        "# 8B model\n",
        "ollama run llama3\n",
        "```\n",
        "\n",
        "\n",
        "The output looks like as follows\n",
        "\n",
        "```\n",
        "$ ollama run llama3\n",
        "pulling manifest\n",
        "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB\n",
        "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB\n",
        "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B\n",
        "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B\n",
        "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B\n",
        "verifying sha256 digest\n",
        "writing manifest\n",
        "removing any unused layers\n",
        "success\n",
        "```\n",
        "\n",
        "- Note that `llama3` refers to the instruction finetuned 8-billion-parameter Llama 3 model\n",
        "\n",
        "- Using ollama with the `\"llama3\"` model (a 8B parameter model) requires 16 GB of RAM; if this is not supported by your machine, you can try the smaller model, such as the 3.8B parameter phi-3 model by setting `model = \"phi-3\"`, which only requires 8 GB of RAM\n",
        "\n",
        "- Alternatively, you can also use the larger 70-billion-parameter Llama 3 model, if your machine supports it, by replacing `llama3` with `llama3:70b`\n",
        "\n",
        "- After the download has been completed, you will see a command line prompt that allows you to chat with the model\n",
        "\n",
        "- Try a prompt like \"What do llamas eat?\", which should return an output similar to the following\n",
        "\n",
        "```\n",
        ">>> What do llamas eat?\n",
        "Llamas are ruminant animals, which means they have a four-chambered\n",
        "stomach and eat plants that are high in fiber. In the wild, llamas\n",
        "typically feed on:\n",
        "1. Grasses: They love to graze on various types of grasses, including tall\n",
        "grasses, wheat, oats, and barley.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b7b341c-ba0e-40bb-a52c-cb328bbd1fe4",
      "metadata": {
        "id": "7b7b341c-ba0e-40bb-a52c-cb328bbd1fe4"
      },
      "source": [
        "- You can end this session using the input `/bye`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faaf3e02-8ca0-4edf-be23-60625a5b14e3",
      "metadata": {
        "id": "faaf3e02-8ca0-4edf-be23-60625a5b14e3"
      },
      "source": [
        "- The following code checks whether the ollama session is running correctly before proceeding to use ollama to evaluate the test set responses we generated in the previous section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "026e8570-071e-48a2-aa38-64d7be35f288",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "026e8570-071e-48a2-aa38-64d7be35f288",
        "outputId": "e30d3533-e1f5-4aa9-b24f-33273fc7b30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama running: True\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter([\"name\"]):\n",
        "        if process_name in proc.info[\"name\"]:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "\n",
        "ollama_running = check_if_running(\"ollama\")\n",
        "\n",
        "if not ollama_running:\n",
        "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
        "print(\"Ollama running:\", check_if_running(\"ollama\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0",
      "metadata": {
        "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0"
      },
      "outputs": [],
      "source": [
        "# This cell is optional; it allows you to restart the notebook\n",
        "# and only run section 7.7 without rerunning any of the previous code\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "file_path = \"instruction-data-with-response.json\"\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    test_data = json.load(file)\n",
        "\n",
        "\n",
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3464705-d026-4594-977f-fb357e51c3a9",
      "metadata": {
        "id": "b3464705-d026-4594-977f-fb357e51c3a9"
      },
      "source": [
        "- Now, an alternative way to the `ollama run` command we used earlier to interact with the model is via its REST API in Python via the following function\n",
        "- Before you run the next cells in this notebook, make sure that ollama is still running (the previous code cells should print `\"Ollama running: True\"`)\n",
        "- Next, run the following code cell to query the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ae0e10-2b28-42ce-8ea2-d9366a58088f",
      "metadata": {
        "id": "e3ae0e10-2b28-42ce-8ea2-d9366a58088f",
        "outputId": "1deef7e7-553f-498b-c970-0f370da2f1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
            "\n",
            "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
            "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
            "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
            "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
            "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and well-being.\n",
            "\n",
            "In the wild, llamas might also eat:\n",
            "\n",
            "1. Leaves: They'll munch on leaves from trees and shrubs, including plants like willow, alder, and birch.\n",
            "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or cottonwood.\n",
            "3. Mosses and lichens: These non-vascular plants can be a tasty snack for llamas.\n",
            "\n",
            "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "def query_model(\n",
        "    prompt,\n",
        "    model=\"llama3\",\n",
        "    url=\"http://localhost:11434/api/chat\"\n",
        "):\n",
        "    # Create the data payload as a dictionary\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {     # Settings below are required for deterministic responses\n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
        "    payload = json.dumps(data).encode(\"utf-8\")\n",
        "\n",
        "    # Create a request object, setting the method to POST and adding necessary headers\n",
        "    request = urllib.request.Request(\n",
        "        url,\n",
        "        data=payload,\n",
        "        method=\"POST\"\n",
        "    )\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "\n",
        "    # Send the request and capture the response\n",
        "    response_data = \"\"\n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        # Read and decode the response\n",
        "        while True:\n",
        "            line = response.readline().decode(\"utf-8\")\n",
        "            if not line:\n",
        "                break\n",
        "            response_json = json.loads(line)\n",
        "            response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data\n",
        "\n",
        "\n",
        "model = \"llama3\"\n",
        "result = query_model(\"What do Llamas eat?\", model)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "207ae28f-0f8c-4fda-aeef-e7e3046249cc",
      "metadata": {
        "id": "207ae28f-0f8c-4fda-aeef-e7e3046249cc"
      },
      "source": [
        "- Now, using the `query_model` function we defined above, we can evaluate the responses of our finetuned model; let's try it out on the first 3 test set responses we looked at in a previous section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b839d4-064d-4178-b2d7-01691b452e5e",
      "metadata": {
        "id": "86b839d4-064d-4178-b2d7-01691b452e5e",
        "outputId": "cf47cf9b-c877-4a5d-c7c9-6ecaadc6ec83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "\n",
            "Score:\n",
            ">> I'd rate the model response \"The car is as fast as a bullet.\" an 85 out of 100.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* The response uses a simile correctly, comparing the speed of the car to something else (in this case, a bullet).\n",
            "* The comparison is relevant and makes sense, as bullets are known for their high velocity.\n",
            "* The phrase \"as fast as\" is used correctly to introduce the simile.\n",
            "\n",
            "The only reason I wouldn't give it a perfect score is that some people might find the comparison slightly less vivid or evocative than others. For example, comparing something to lightning (as in the original response) can be more dramatic and attention-grabbing. However, \"as fast as a bullet\" is still a strong and effective simile that effectively conveys the idea of the car's speed.\n",
            "\n",
            "Overall, I think the model did a great job!\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "\n",
            "Score:\n",
            ">> I'd score this model response as 40 out of 100.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* The model correctly identifies that thunderstorms are related to clouds (correctly identifying the type of phenomenon).\n",
            "* However, it incorrectly specifies the type of cloud associated with thunderstorms. Cumulus clouds are not typically associated with thunderstorms; cumulonimbus clouds are.\n",
            "* The response lacks precision and accuracy in its description.\n",
            "\n",
            "Overall, while the model attempts to address the instruction, it provides an incorrect answer, which is a significant error.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "\n",
            "Score:\n",
            ">> I'd rate my own response as 95 out of 100. Here's why:\n",
            "\n",
            "* The response accurately answers the question by naming the author of 'Pride and Prejudice' as Jane Austen.\n",
            "* The response is concise and clear, making it easy to understand.\n",
            "* There are no grammatical errors or ambiguities that could lead to confusion.\n",
            "\n",
            "The only reason I wouldn't give myself a perfect score is that the response is slightly redundant - it's not necessary to rephrase the question in the answer. A more concise response would be simply \"Jane Austen.\"\n",
            "\n",
            "-------------------------\n"
          ]
        }
      ],
      "source": [
        "for entry in test_data[:3]:\n",
        "    prompt = (\n",
        "        f\"Given the input `{format_input(entry)}` \"\n",
        "        f\"and correct output `{entry['output']}`, \"\n",
        "        f\"score the model response `{entry['model_response']}`\"\n",
        "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "    )\n",
        "    print(\"\\nDataset response:\")\n",
        "    print(\">>\", entry['output'])\n",
        "    print(\"\\nModel response:\")\n",
        "    print(\">>\", entry[\"model_response\"])\n",
        "    print(\"\\nScore:\")\n",
        "    print(\">>\", query_model(prompt))\n",
        "    print(\"\\n-------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b114fd65-9cfb-45f6-ab74-8331da136bf3",
      "metadata": {
        "id": "b114fd65-9cfb-45f6-ab74-8331da136bf3"
      },
      "source": [
        "- As we can see, the Llama 3 model provides a reasonable evaluation and also gives partial points if a model is not entirely correct, as we can see based on the \"cumulus cloud\" answer\n",
        "- Note that the previous prompt returns very verbose evaluations; we can tweak the prompt to generate integer responses in the range between 0 and 100 (where 100 is best) to calculate an average score for our model\n",
        "- The evaluation of the 110 entries in the test set takes about 1 minute on an M3 MacBook Air laptop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d7bca69-97c4-47a5-9aa0-32f116fa37eb",
      "metadata": {
        "id": "9d7bca69-97c4-47a5-9aa0-32f116fa37eb",
        "outputId": "18100b24-a9bc-4da8-a101-0a1953b1ecb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring entries: 100%|████████████████████████| 110/110 [01:10<00:00,  1.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of scores: 110 of 110\n",
            "Average score: 50.32\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
        "    scores = []\n",
        "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
        "        prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and correct output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry[json_key]}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "            f\"Respond with the integer number only.\"\n",
        "        )\n",
        "        score = query_model(prompt, model)\n",
        "        try:\n",
        "            scores.append(int(score))\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert score: {score}\")\n",
        "            continue\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "scores = generate_model_scores(test_data, \"model_response\")\n",
        "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
        "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2",
      "metadata": {
        "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2"
      },
      "source": [
        "- Our model achieves an average score of above 50, which we can use as a reference point to compare the model to other models or to try out other training settings that may improve the model\n",
        "- Note that ollama is not fully deterministic across operating systems (as of this writing), so the numbers you are getting might slightly differ from the ones shown above"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94",
      "metadata": {
        "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94"
      },
      "source": [
        "- For reference, the original\n",
        "  - Llama 3 8B base model achieves a score of 58.51\n",
        "  - Llama 3 8B instruct model achieves a score of 82.65"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "412d7325-284a-446c-92a1-5aa8acc52dee",
      "metadata": {
        "id": "412d7325-284a-446c-92a1-5aa8acc52dee"
      },
      "source": [
        "## 7.9 Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tIbNMluCDjVM",
      "metadata": {
        "id": "tIbNMluCDjVM"
      },
      "source": [
        "### 7.9.1 What's next\n",
        "\n",
        "- This marks the final chapter of this book\n",
        "- We covered the major steps of the LLM development cycle: implementing an LLM architecture, pretraining an LLM, and finetuning it\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/final-overview.webp?1\" width=500px>\n",
        "\n",
        "- An optional step that is sometimes followed after instruction finetuning, as described in this chapter, is preference finetuning\n",
        "- Preference finetuning process can be particularly useful for customizing a model to better align with specific user preferences; see the [../04_preference-tuning-with-dpo](../04_preference-tuning-with-dpo) folder if you are interested in this\n",
        "\n",
        "- This GitHub repository also contains a large selection of additional bonus material you may enjoy; for more information, please see the [Bonus Material](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material) section on this repository's README page\n",
        "\n",
        "### 7.9.2 Staying up to date in a fast-moving field\n",
        "\n",
        "- No code in this section\n",
        "\n",
        "### 7.9.3 Final words\n",
        "\n",
        "- I hope you enjoyed this journey of implementing an LLM from the ground up and coding the pretraining and finetuning functions\n",
        "- In my opinion, implementing an LLM from scratch is the best way to understand how LLMs work; I hope you gained a better understanding through this approach\n",
        "- While this book serves educational purposes, you may be interested in using different and more powerful LLMs for real-world applications\n",
        "  - For this, you may consider popular tools such as axolotl ([https://github.com/OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)) or LitGPT ([https://github.com/Lightning-AI/litgpt](https://github.com/Lightning-AI/litgpt)), which I help developing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9853e7f-a81a-4806-9728-be1690807185",
      "metadata": {
        "id": "f9853e7f-a81a-4806-9728-be1690807185"
      },
      "source": [
        "## Summary and takeaways\n",
        "\n",
        "- See the [./gpt_instruction_finetuning.py](./gpt_instruction_finetuning.py) script, a self-contained script for classification finetuning\n",
        "- [./ollama_evaluate.py](./ollama_evaluate.py) is a standalone script based on section 7.8 that evaluates a JSON file containing \"output\" and \"response\" keys via Ollama and Llama 3\n",
        "- The [./load-finetuned-model.ipynb](./load-finetuned-model.ipynb) notebook illustrates how to load the finetuned model in a new session\n",
        "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9cc51ec-e06c-4470-b626-48401a037851",
      "metadata": {
        "id": "b9cc51ec-e06c-4470-b626-48401a037851"
      },
      "source": [
        "## What's next?\n",
        "\n",
        "- Congrats on completing the book; in case you are looking for additional resources, I added several bonus sections to this GitHub repository that you might find interesting\n",
        "- The complete list of bonus materials can be viewed in the main README's [Bonus Material](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material) section\n",
        "- To highlight a few of my favorites:\n",
        "  1. [Direct Preference Optimization (DPO) for LLM Alignment (From Scratch)](../04_preference-tuning-with-dpo/dpo-from-scratch.ipynb) implements a popular preference tuning mechanism to align the model from this chapter more closely with human preferences\n",
        "  2. [Llama 3.2 From Scratch (A Standalone Notebook)](../../ch05/07_gpt_to_llama/standalone-llama32.ipynb), a from-scratch implementation of Meta AI's popular Llama 3.2, including loading the official pretrained weights; if you are up to some additional experiments, you can replace the `GPTModel` model in each of the chapters with the `Llama3Model` class (it should work as a 1:1 replacement)\n",
        "  3. [Converting GPT to Llama](../../ch05/07_gpt_to_llama) contains code with step-by-step guides that explain the differences between GPT-2 and the various Llama models\n",
        "  4. [Understanding the Difference Between Embedding Layers and Linear Layers](../../ch02/03_bonus_embedding-vs-matmul/embeddings-and-linear-layers.ipynb) is a conceptual explanation illustrating that the `Embedding` layer in PyTorch, which we use at the input stage of an LLM, is mathematically equivalent to a linear layer applied to one-hot encoded data\n",
        "- Happy further reading!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "033a21ee3ce04a0b8dcfed1d156b0c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13836d0d50a84f9781f8eac797108dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d51f1dda0b14d04bd84371e206b5735",
            "max": 18949833,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b19f68e6d5145ceac263e0fd0d3bcf4",
            "value": 18949833
          }
        },
        "19eec44a2e774809a8a21f81e477357b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a1d387c7ce9458ab5fc48b1474eee54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c379942a4a747f6bfe98a0e04b79566": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f11504bcc0646ee96ef18d833e25692": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19eec44a2e774809a8a21f81e477357b",
            "max": 384,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_505100a9618b4d9e9455b04a9a7e53b3",
            "value": 384
          }
        },
        "4a399b40db8f486795c217ee54a5630a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65cbdc4dbb6c41509d0bf4720f13e11d",
            "max": 52005,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_945d587d7a424a21b0109acf79436001",
            "value": 52005
          }
        },
        "4cde55c5fcc0437b8a239d6164333292": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d51f1dda0b14d04bd84371e206b5735": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "505100a9618b4d9e9455b04a9a7e53b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53997b1438324aafa09243fea116a6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ab715769364edea60cdf235fc174ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56073cd05332458ebe7a31f5cd45883e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58e0005fd18a41e99bbf591943819b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e2ee6f7e3ed49ebaaa2db1375098a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56073cd05332458ebe7a31f5cd45883e",
            "placeholder": "​",
            "style": "IPY_MODEL_3c379942a4a747f6bfe98a0e04b79566",
            "value": " 18.9M/18.9M [00:01&lt;00:00, 10.3MB/s]"
          }
        },
        "6254d34f8fc74b0caec6600a4e31ded4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53997b1438324aafa09243fea116a6bc",
            "placeholder": "​",
            "style": "IPY_MODEL_033a21ee3ce04a0b8dcfed1d156b0c6e",
            "value": " 384/384 [00:00&lt;00:00, 7.88kB/s]"
          }
        },
        "62ee1e5991df4758b35823f3adc5ccf4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64df8ad77ee84b0ebd434d0497548b75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65cbdc4dbb6c41509d0bf4720f13e11d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ea5308bc6d04a55ba2e978a50df6853": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73890def4a65469f9843a58ec75e3d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea22ec18d99b4aa7aebc5c4fed7a177f",
              "IPY_MODEL_3f11504bcc0646ee96ef18d833e25692",
              "IPY_MODEL_6254d34f8fc74b0caec6600a4e31ded4"
            ],
            "layout": "IPY_MODEL_cc5dcd93fc71469687c63eb112bfcae0"
          }
        },
        "8b19f68e6d5145ceac263e0fd0d3bcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "931d2a02a3044ed2beaf6e556df2904f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0278cab6425484db469ea46e2005896",
              "IPY_MODEL_4a399b40db8f486795c217ee54a5630a",
              "IPY_MODEL_efd8d741e52144ae85ea7c3843d6a89f"
            ],
            "layout": "IPY_MODEL_3a1d387c7ce9458ab5fc48b1474eee54"
          }
        },
        "945d587d7a424a21b0109acf79436001": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a733e306c8d7454b978dcb4d6f283e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58e0005fd18a41e99bbf591943819b5d",
            "placeholder": "​",
            "style": "IPY_MODEL_53ab715769364edea60cdf235fc174ee",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "ab74f8f4a3fd4bd48d4769bf31f45bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0278cab6425484db469ea46e2005896": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff5b51e53f964204ad46acaa4bb1eada",
            "placeholder": "​",
            "style": "IPY_MODEL_6ea5308bc6d04a55ba2e978a50df6853",
            "value": "Generating train split: 100%"
          }
        },
        "cc5dcd93fc71469687c63eb112bfcae0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d95197cfa8b441a1974fd9f8a2d8c5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a733e306c8d7454b978dcb4d6f283e72",
              "IPY_MODEL_13836d0d50a84f9781f8eac797108dd4",
              "IPY_MODEL_5e2ee6f7e3ed49ebaaa2db1375098a99"
            ],
            "layout": "IPY_MODEL_62ee1e5991df4758b35823f3adc5ccf4"
          }
        },
        "e10fc7b48e334def92df6aa38433fbf0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea22ec18d99b4aa7aebc5c4fed7a177f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e10fc7b48e334def92df6aa38433fbf0",
            "placeholder": "​",
            "style": "IPY_MODEL_ab74f8f4a3fd4bd48d4769bf31f45bcf",
            "value": "README.md: 100%"
          }
        },
        "efd8d741e52144ae85ea7c3843d6a89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64df8ad77ee84b0ebd434d0497548b75",
            "placeholder": "​",
            "style": "IPY_MODEL_4cde55c5fcc0437b8a239d6164333292",
            "value": " 52005/52005 [00:00&lt;00:00, 64097.47 examples/s]"
          }
        },
        "ff5b51e53f964204ad46acaa4bb1eada": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
