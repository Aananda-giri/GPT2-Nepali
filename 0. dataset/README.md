# Datasets

- NepBERTa data was pre-tokenized (context len. 512) and utilized for pre-training GPT2-Nepali model.

# Other Available Datasets

**1. [NepBERTa Dataset](https://drive.google.com/drive/folders/1oLvfKb663wZuw-n36ymHsSYAqeSHmKzo)**

    * Size: 12.5 GB of cleaned Nepali dataset

Description: A corpus of Nepali web pages crawled and processed to create a high-quality dataset.

**2. [IRIISNEPAL/Nepali-Text-Corpus](https://huggingface.co/datasets/IRIISNEPAL/Nepali-Text-Corpus)**

    * Size: 27.5 GB of cleaned Nepali dataset

Description: A comprehensive dataset crawled and cleaned from various Nepali web pages, providing a robust resource for language modeling.

**3. [Oscar-2021](https://huggingface.co/datasets/oscar-corpus/OSCAR-2201)**

    * Size: 3.7 GB of Nepali dataset

- Description: A multilingual corpus extracted from Common Crawl, including diverse Nepali texts.

**4. Combined Corpus [(on kaggle)](https://www.kaggle.com/code/reganmaharjan/nepali-combined-corpus)**

Description: A dataset combining various Nepali text sources, designed to provide a rich corpus for natural language processing tasks.
